\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Keep aspect ratio if custom image width or height is specified
    \setkeys{Gin}{keepaspectratio}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Proyecto\_3\_HiperparametrizaciÃ³n\_con\_Optuna\_en\_modelos\_de\_aprendizaje\_profundo}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{proyecto-3-hiperparametrizaciuxf3n-con-optuna-en-modelos-de-aprendizaje-profundo}{%
\section{Proyecto 3 HiperparametrizaciÃ³n con Optuna en modelos de
aprendizaje
profundo}\label{proyecto-3-hiperparametrizaciuxf3n-con-optuna-en-modelos-de-aprendizaje-profundo}}

    \hypertarget{introducciuxf3n-a-optuna-y-configuraciuxf3n-inicial}{%
\subsection{1. IntroducciÃ³n a optuna y configuraciÃ³n
inicial:}\label{introducciuxf3n-a-optuna-y-configuraciuxf3n-inicial}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Estudiar los fundamentos y caracterÃ­sticas de Optuna, incluyendo su
  arquitectura y mÃ©todos de optimizaciÃ³n. \textbackslash{}
\item
  Preparar un entorno de desarrollo en PyTorch y configurar Optuna para
  integrarse con modelos de aprendizaje profundo.
\end{enumerate}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \hypertarget{introducciuxf3n}{%
\subsubsection{IntroducciÃ³n}\label{introducciuxf3n}}

    La bÃºsqueda de hiperparÃ¡metros forma parte de casi todos los proyectos
de aprendizaje automÃ¡tico y aprendizaje profundo. Cuando seleccionamos
un modelo candidato, nos aseguramos de que generalize a los datos de
prueba de la mejor manera posible.

Seleccionar manualmente los mejores hiperparÃ¡metros es fÃ¡cil si se trata
de un modelo sencillo como la regresiÃ³n lineal. Para modelos complejos
como las redes neuronales, el ajuste manual es difÃ­cil.

Por ejemplo, si entrenamos una red neuronal con sÃ³lo capas lineales,
aquÃ­ tenemos un conjunto potencial de hiperparÃ¡metros:

    \begin{itemize}
\tightlist
\item
  NÃºmero de capas
\item
  Unidades por capa
\item
  FunciÃ³n de activaciÃ³n
\item
  Tasa de aprendizaje
\item
  etc.
\end{itemize}

    A menudo, para optimizar los hiperparÃ¡metros se utilizan mÃ©todos Grid
Search y Random Search.

    Por ejemplo, digamos que tenemos 3 valores candidatos para cada una de
esas 4 variables, acabamos con 3\^{}4 = 81 experimentos. Para redes mÃ¡s
grandes y mÃ¡s valores candidatos, este nÃºmero se vuelve abrumador.

    Estos dos enfoques consumen mucho tiempo y recursos. Los algoritmos de
aprendizaje profundo actuales a menudo contienen muchos hiperparÃ¡metros,
y se tarda dÃ­as, semanas en entrenar un buen modelo. Simplemente no es
posible forzar Ñombinaciones de hiperparÃ¡metros y entrenar modelos
separados para cada uno sin ninguna optimizaciÃ³n.

    \hypertarget{optuna}{%
\subsubsection{Optuna}\label{optuna}}

    Para esto se creo \textbf{Optuna}, que es una biblioteca de Python
utilizada para la optimizaciÃ³n de hiperparÃ¡metros.

    \textbf{Optuna combina mecanismos de muestreo (sampling) y poda
(pruning) para proporcionar una optimizaciÃ³n eficiente de los
hiperparÃ¡metros.}

    Optuna utiliza el muestreo para explorar el espacio de bÃºsqueda de
hiperparÃ¡metros. Sugiere nuevos valores de hiperparÃ¡metros basÃ¡ndose en
ensayos anteriores y en el algoritmo de optimizaciÃ³n utilizado. Ofrece
distintas estrategias de muestreo:

\begin{itemize}
\tightlist
\item
  Grid Search implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.GridSampler.html\#optuna.samplers.GridSampler}{GridSampler}
\item
  Random Search implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.RandomSampler.html\#optuna.samplers.RandomSampler}{RandomSampler}
\item
  Tree-structured Parzen Estimator algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html\#optuna.samplers.TPESampler}{TPESampler}
\item
  CMA-ES based algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html\#optuna.samplers.CmaEsSampler}{CmaEsSampler}
\item
  Algoritmo para activar parÃ¡metros fijos parciales implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.PartialFixedSampler.html\#optuna.samplers.PartialFixedSampler}{PartialFixedSampler}
\item
  Non-dominated Sorting Genetic Algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.NSGAIISampler.html\#optuna.samplers.NSGAIISampler}{NSGAIISampler}
\item
  uasi Monte Carlo sampling algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.QMCSampler.html\#optuna.samplers.QMCSampler}{QMCSampler}
\end{itemize}

    Tambien proporciona mecanismos para detener y podar tempranamente
ensayos poco prometedores. Supervisa continuamente el progreso de las
pruebas y elimina aquellas que probablemente no produzcan mejores
resultados, ahorrando tiempo y recursos computacionales. Las decisiones
de poda se toman con base en los resultados intermedios informados por
la funciÃ³n objetivo durante la evaluaciÃ³n de un ensayo.

    \hypertarget{caracteruxedsticas-principales-de-optuna}{%
\subsubsection{CaracterÃ­sticas principales de
Optuna:}\label{caracteruxedsticas-principales-de-optuna}}

    SegÃºn los \href{https://optuna.org/}{autores de Optuna}, son tres las
caracterÃ­sticas que la hacen destacar: - Eager search spaces: Automated
search for optimal hyperparameters using Python conditionals, loops, and
syntax - State-of-the-art algorithms: Efficiently search large spaces
and prune unpromising trials for faster results - Easy parallelization:
Parallelize hyperparameter searches over multiple threads or processes
without modifying code

    \hypertarget{flujo-de-trabajo}{%
\subsubsection{Flujo de trabajo}\label{flujo-de-trabajo}}

    El flujo de trabajo de Optuna se resuelve en torno a dos tÃ©rminos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ensayo (Trial): Una Ãºnica llamada a una funciÃ³n objetivo.
\item
  Estudio (Study): OptimizaciÃ³n de hiperparÃ¡metros basada en una funciÃ³n
  objetivo. Un estudio tiene como objetivo determinar el conjunto ideal
  de valores de hiperparÃ¡metros mediante la realizaciÃ³n de varios
  ensayos.
\end{enumerate}

    \hypertarget{integraciuxf3n-de-optuna-y-pytorch}{%
\subsubsection{IntegraciÃ³n de Optuna y
PyTorch}\label{integraciuxf3n-de-optuna-y-pytorch}}

    Ahora, vamos a desglosar el proceso de optimizaciÃ³n de hiperparÃ¡metros
con Optuna.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{torchvision}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting torchvision
  Downloading torchvision-0.18.1-cp312-cp312-manylinux1\_x86\_64.whl.metadata (6.6
kB)
Requirement already satisfied: numpy in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torchvision) (2.0.0)
Requirement already satisfied: torch==2.3.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torchvision) (2.3.1)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)
  Downloading pillow-10.3.0-cp312-cp312-manylinux\_2\_28\_x86\_64.whl.metadata (9.2
kB)
Requirement already satisfied: filelock in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (3.15.3)
Requirement already satisfied: typing-extensions>=4.8.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (4.12.2)
Requirement already satisfied: sympy in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision) (1.12.1)
Requirement already satisfied: networkx in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (3.3)
Requirement already satisfied: jinja2 in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision) (3.1.4)
Requirement already satisfied: fsspec in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision)
(2024.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-nvjitlink-cu12 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision) (12.5.40)
Requirement already satisfied: MarkupSafe>=2.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from jinja2->torch==2.3.1->torchvision) (2.1.5)
Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from sympy->torch==2.3.1->torchvision) (1.3.0)
Downloading torchvision-0.18.1-cp312-cp312-manylinux1\_x86\_64.whl (7.0 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{7.0/7.0 MB} \textcolor{ansi-red}{1.4 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading pillow-10.3.0-cp312-cp312-manylinux\_2\_28\_x86\_64.whl (4.5 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{4.5/4.5 MB} \textcolor{ansi-red}{1.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:010m
Installing collected packages: pillow, torchvision
Successfully installed pillow-10.3.0 torchvision-0.18.1
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{optuna}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting optuna
  Using cached optuna-3.6.1-py3-none-any.whl.metadata (17 kB)
Collecting alembic>=1.5.0 (from optuna)
  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)
Collecting colorlog (from optuna)
  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from optuna)
  Using cached
numpy-2.0.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata
(60 kB)
Requirement already satisfied: packaging>=20.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from optuna) (24.1)
Collecting sqlalchemy>=1.3.0 (from optuna)
  Using cached SQLAlchemy-2.0.31-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (9.6 kB)
Collecting tqdm (from optuna)
  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)
     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{âââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{57.6/57.6 kB} \textcolor{ansi-red}{728.0 kB/s} eta \textcolor{ansi-cyan}{0:00:00}MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Requirement already satisfied: PyYAML in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from optuna) (6.0.1)
Collecting Mako (from alembic>=1.5.0->optuna)
  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)
  Using cached typing\_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)
  Using cached greenlet-3.0.3-cp312-cp312-
manylinux\_2\_24\_x86\_64.manylinux\_2\_28\_x86\_64.whl.metadata (3.8 kB)
Requirement already satisfied: MarkupSafe>=0.9.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from Mako->alembic>=1.5.0->optuna) (2.1.5)
Using cached optuna-3.6.1-py3-none-any.whl (380 kB)
Using cached alembic-1.13.1-py3-none-any.whl (233 kB)
Using cached
SQLAlchemy-2.0.31-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl
(3.2 MB)
Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)
Using cached
numpy-2.0.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (19.0 MB)
Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{78.3/78.3 kB} \textcolor{ansi-red}{2.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}
Using cached
greenlet-3.0.3-cp312-cp312-manylinux\_2\_24\_x86\_64.manylinux\_2\_28\_x86\_64.whl (625
kB)
Using cached typing\_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached Mako-1.3.5-py3-none-any.whl (78 kB)
Installing collected packages: typing-extensions, tqdm, numpy, Mako, greenlet,
colorlog, sqlalchemy, alembic, optuna
Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 greenlet-3.0.3
numpy-2.0.0 optuna-3.6.1 sqlalchemy-2.0.31 tqdm-4.66.4 typing-extensions-4.12.2
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{torch}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting torch
  Downloading torch-2.3.1-cp312-cp312-manylinux1\_x86\_64.whl.metadata (26 kB)
Collecting filelock (from torch)
  Downloading filelock-3.15.3-py3-none-any.whl.metadata (2.9 kB)
Requirement already satisfied: typing-extensions>=4.8.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch) (4.12.2)
Collecting sympy (from torch)
  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch)
  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)
Requirement already satisfied: jinja2 in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch) (3.1.4)
Collecting fsspec (from torch)
  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_nvrtc\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_runtime\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_cupti\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)
  Downloading nvidia\_cudnn\_cu12-8.9.2.26-py3-none-manylinux1\_x86\_64.whl.metadata
(1.6 kB)
Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)
  Downloading nvidia\_cublas\_cu12-12.1.3.1-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)
  Downloading nvidia\_cufft\_cu12-11.0.2.54-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.2.106 (from torch)
  Downloading nvidia\_curand\_cu12-10.3.2.106-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)
  Downloading nvidia\_cusolver\_cu12-11.4.5.107-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)
  Downloading nvidia\_cusparse\_cu12-12.1.0.106-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12==2.20.5 (from torch)
  Downloading nvidia\_nccl\_cu12-2.20.5-py3-none-manylinux2014\_x86\_64.whl.metadata
(1.8 kB)
Collecting nvidia-nvtx-cu12==12.1.105 (from torch)
  Downloading nvidia\_nvtx\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl.metadata
(1.7 kB)
Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)
  Downloading nvidia\_nvjitlink\_cu12-12.5.40-py3-none-
manylinux2014\_x86\_64.whl.metadata (1.5 kB)
Requirement already satisfied: MarkupSafe>=2.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from jinja2->torch) (2.1.5)
Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)
  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Downloading torch-2.3.1-cp312-cp312-manylinux1\_x86\_64.whl (779.1 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{779.1/779.1 MB} \textcolor{ansi-red}{3.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:04m
Downloading nvidia\_cublas\_cu12-12.1.3.1-py3-none-manylinux1\_x86\_64.whl
(410.6 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{410.6/410.6 MB} \textcolor{ansi-red}{4.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:02
Downloading nvidia\_cuda\_cupti\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl
(14.1 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{14.1/14.1 MB} \textcolor{ansi-red}{6.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading nvidia\_cuda\_nvrtc\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl
(23.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{23.7/23.7 MB} \textcolor{ansi-red}{6.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading nvidia\_cuda\_runtime\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl (823 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{823.6/823.6 kB} \textcolor{ansi-red}{7.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01
Downloading nvidia\_cudnn\_cu12-8.9.2.26-py3-none-manylinux1\_x86\_64.whl
(731.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{731.7/731.7 MB} \textcolor{ansi-red}{3.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:03
Downloading nvidia\_cufft\_cu12-11.0.2.54-py3-none-manylinux1\_x86\_64.whl
(121.6 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{121.6/121.6 MB} \textcolor{ansi-red}{5.7 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_curand\_cu12-10.3.2.106-py3-none-manylinux1\_x86\_64.whl
(56.5 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{56.5/56.5 MB} \textcolor{ansi-red}{6.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_cusolver\_cu12-11.4.5.107-py3-none-manylinux1\_x86\_64.whl
(124.2 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{124.2/124.2 MB} \textcolor{ansi-red}{5.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_cusparse\_cu12-12.1.0.106-py3-none-manylinux1\_x86\_64.whl
(196.0 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{196.0/196.0 MB} \textcolor{ansi-red}{4.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nccl\_cu12-2.20.5-py3-none-manylinux2014\_x86\_64.whl
(176.2 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{176.2/176.2 MB} \textcolor{ansi-red}{5.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nvtx\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl (99
kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{99.1/99.1 kB} \textcolor{ansi-red}{1.7 MB/s} eta \textcolor{ansi-cyan}{0:00:00} MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Downloading filelock-3.15.3-py3-none-any.whl (16 kB)
Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{176.9/176.9 kB} \textcolor{ansi-red}{3.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}\textcolor{ansi-cyan}{0:00:01}
Downloading networkx-3.3-py3-none-any.whl (1.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{1.7/1.7 MB} \textcolor{ansi-red}{8.0 MB/s} eta \textcolor{ansi-cyan}{0:00:00}[31m8.2 MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{5.7/5.7 MB} \textcolor{ansi-red}{6.4 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{536.2/536.2 kB} \textcolor{ansi-red}{7.2 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nvjitlink\_cu12-12.5.40-py3-none-
manylinux2014\_x86\_64.whl (21.3 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{21.3/21.3 MB} \textcolor{ansi-red}{6.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-
nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-
cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-
cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-
cu12, nvidia-cusolver-cu12, torch
Successfully installed filelock-3.15.3 fsspec-2024.6.0 mpmath-1.3.0 networkx-3.3
nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-
cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26
nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-
cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-
nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sympy-1.12.1 torch-2.3.1
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{matplotlib}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting matplotlib
  Downloading matplotlib-3.9.0-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (11 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Downloading contourpy-1.2.1-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (5.8 kB)
Collecting cycler>=0.10 (from matplotlib)
  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Downloading fonttools-4.53.0-cp312-cp312-
manylinux\_2\_5\_x86\_64.manylinux1\_x86\_64.manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_6
4.whl.metadata (162 kB)
     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{âââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{162.2/162.2 kB} \textcolor{ansi-red}{906.0 kB/s} eta \textcolor{ansi-cyan}{0:00:00} kB/s eta
\textcolor{ansi-cyan}{0:00:01}:01
Collecting kiwisolver>=1.3.1 (from matplotlib)
  Downloading kiwisolver-1.4.5-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (6.4 kB)
Requirement already satisfied: numpy>=1.23 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (2.0.0)
Requirement already satisfied: packaging>=20.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (24.1)
Requirement already satisfied: pillow>=8 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (10.3.0)
Collecting pyparsing>=2.3.1 (from matplotlib)
  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)
Requirement already satisfied: python-dateutil>=2.7 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from python-dateutil>=2.7->matplotlib) (1.16.0)
Downloading
matplotlib-3.9.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (8.3
MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{8.3/8.3 MB} \textcolor{ansi-red}{2.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading
contourpy-1.2.1-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (309
kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{309.2/309.2 kB} \textcolor{ansi-red}{13.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00} eta
\textcolor{ansi-cyan}{-:--:--}
Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Downloading fonttools-4.53.0-cp312-cp312-
manylinux\_2\_5\_x86\_64.manylinux1\_x86\_64.manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_6
4.whl (4.9 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{4.9/4.9 MB} \textcolor{ansi-red}{5.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading
kiwisolver-1.4.5-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (1.5
MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{1.5/1.5 MB} \textcolor{ansi-red}{8.2 MB/s} eta \textcolor{ansi-cyan}{0:00:00}[31m9.2 MB/s eta
\textcolor{ansi-cyan}{0:00:01}m
Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{ââââââââââââââââââââââââââââââââââââââââ}
\textcolor{ansi-green}{103.2/103.2 kB} \textcolor{ansi-red}{11.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00}
Installing collected packages: pyparsing, kiwisolver, fonttools, cycler,
contourpy, matplotlib
Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0
kiwisolver-1.4.5 matplotlib-3.9.0 pyparsing-3.1.2
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{time}
\PY{k+kn}{import} \PY{n+nn}{copy}

\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}

\PY{k+kn}{import} \PY{n+nn}{torchvision}
\PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k+kn}{import} \PY{n}{datasets}\PY{p}{,} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}

\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{optimizaciuxf3n-de-un-modelo-de-clasificaciuxf3n-de-imuxe1genes}{%
\subsection{2. OptimizaciÃ³n de un modelo de clasificaciÃ³n de
imÃ¡genes:}\label{optimizaciuxf3n-de-un-modelo-de-clasificaciuxf3n-de-imuxe1genes}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Implementar un modelo convencional como ResNet o VGG en PyTorch.
  \textbackslash{}
\item
  Utilizar Optuna para optimizar hiperparÃ¡metros como tasa de
  aprendizaje, tamaÃ±o de lote, y configuraciones especÃ­ficas de capas.
  \textbackslash{}
\item
  Evaluar las mejoras en precisiÃ³n y tiempo de entrenamiento tras la
  optimizaciÃ³n de hiperparÃ¡metros
\end{enumerate}

    El modelo SimpleVGG define capas convolucionales seguidas de capas de
pooling y capas completamente conectadas para la clasificaciÃ³n. La
funciÃ³n objetivo (objective) carga un subconjunto del conjunto de datos
CIFAR10, define hiperparÃ¡metros a optimizar con Optuna, entrena el
modelo y evalÃºa su precisiÃ³n en un conjunto de prueba mÃ¡s pequeÃ±o.
Optuna se utiliza para encontrar los mejores hiperparÃ¡metros en un
nÃºmero limitado de pruebas (n\_trials).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{transforms} \PY{k}{as} \PY{n+nn}{transforms}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{as} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}

\PY{c+c1}{\PYZsh{} Modelo VGG}
\PY{k}{class} \PY{n+nc}{SimpleVGG}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{SimpleVGG}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128} \PY{o}{*} \PY{l+m+mi}{4} \PY{o}{*} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{)}
        \PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Definimos la funciÃ³n objetivo para optimizar con Optuna}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Cargamos un subconjunto del dataset CIFAR10}
    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}train} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)} \PY{c+c1}{\PYZsh{} download=True}
    \PY{n}{cifar10\PYZus{}test} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Usamos un subconjunto mÃ¡s pequeÃ±o del dataset}
    \PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{2000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{2000}\PY{p}{]}\PY{p}{)}
    \PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{500}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{500}\PY{p}{]}\PY{p}{)}

    \PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{testloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos los hiperparÃ¡metros a optimizar}
    \PY{n}{lr} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{weight\PYZus{}decay} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{momentum} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{momentum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos el modelo, el optimizador y la funciÃ³n de pÃ©rdida}
    \PY{n}{model} \PY{o}{=} \PY{n}{SimpleVGG}\PY{p}{(}\PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
    \PY{n}{optimizer} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{SGD}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{,} \PY{n}{momentum}\PY{o}{=}\PY{n}{momentum}\PY{p}{,} \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{weight\PYZus{}decay}\PY{p}{)}
    \PY{n}{loss\PYZus{}fn} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Entrenamos el modelo por una Ã©poca}
    \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{trainloader}\PY{p}{:}
        \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}
        \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        \PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fn}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{target}\PY{p}{)}
        \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
        \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Evaluamos el modelo en el conjunto de prueba}
    \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
    \PY{n}{correct} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{testloader}\PY{p}{:}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{pred} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keepdim}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            \PY{n}{correct} \PY{o}{+}\PY{o}{=} \PY{n}{pred}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{target}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{pred}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Calculamos la precisiÃ³n en el conjunto de prueba y devolverla como el valor objetivo para Optuna}
    \PY{n}{accuracy} \PY{o}{=} \PY{n}{correct} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{testloader}\PY{o}{.}\PY{n}{dataset}\PY{p}{)}
    \PY{k}{return} \PY{n}{accuracy}

\PY{c+c1}{\PYZsh{} Ejecutamos el estudio de Optuna para optimizar los hiperparÃ¡metros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{maximize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}  \PY{c+c1}{\PYZsh{} NÃºmero reducido de pruebas por simplicidad}

\PY{c+c1}{\PYZsh{} Imprimimos los mejores hiperparÃ¡metros y el mejor valor objetivo encontrado por Optuna}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ğğğ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores hiperparÃ¡metros: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor objetivo: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 07:01:28,335] A new study created in memory with name: no-
name-c5cb197f-cc90-4c1b-965c-48768eb6ad3e
[I 2024-06-20 07:01:29,995] Trial 0 finished with value: 0.124 and parameters:
\{'lr': 0.0013185037936517044, 'weight\_decay': 1.0101876084844885e-05,
'momentum': 0.31937225365824595\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:31,628] Trial 1 finished with value: 0.112 and parameters:
\{'lr': 0.0069775700774503385, 'weight\_decay': 1.7158918060121343e-05,
'momentum': 0.777572700493663\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:33,215] Trial 2 finished with value: 0.114 and parameters:
\{'lr': 0.000603989798307354, 'weight\_decay': 0.0003455069810528488, 'momentum':
0.9677030275876205\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:34,810] Trial 3 finished with value: 0.094 and parameters:
\{'lr': 0.00013414570624012488, 'weight\_decay': 0.017267488501468326, 'momentum':
0.9522947167311789\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:36,404] Trial 4 finished with value: 0.096 and parameters:
\{'lr': 0.0010732445095242844, 'weight\_decay': 0.011335276993393881, 'momentum':
0.7190933888877701\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:38,015] Trial 5 finished with value: 0.14 and parameters:
\{'lr': 0.014285162980527384, 'weight\_decay': 0.00016529654230712488, 'momentum':
0.4701801898545127\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:39,629] Trial 6 finished with value: 0.114 and parameters:
\{'lr': 0.01996216276609492, 'weight\_decay': 0.0007625124257630504, 'momentum':
0.6777808179202709\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:41,211] Trial 7 finished with value: 0.114 and parameters:
\{'lr': 0.00048446766440926364, 'weight\_decay': 0.0002085832437380734,
'momentum': 0.3666190394436756\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:42,846] Trial 8 finished with value: 0.114 and parameters:
\{'lr': 0.0005399413956820914, 'weight\_decay': 0.00018445293075448918,
'momentum': 0.6165325947948295\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:44,529] Trial 9 finished with value: 0.118 and parameters:
\{'lr': 0.00598216984259799, 'weight\_decay': 0.04913580697800302, 'momentum':
0.8526936603961539\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:46,156] Trial 10 finished with value: 0.096 and parameters:
\{'lr': 0.07706220685173414, 'weight\_decay': 0.003245565578180795, 'momentum':
0.048390421090106384\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:47,797] Trial 11 finished with value: 0.082 and parameters:
\{'lr': 0.026709407462641235, 'weight\_decay': 1.2567345579514115e-05, 'momentum':
0.3578085575017036\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:49,423] Trial 12 finished with value: 0.092 and parameters:
\{'lr': 0.00220325706718249, 'weight\_decay': 5.506630406102414e-05, 'momentum':
0.2390763704654537\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:51,125] Trial 13 finished with value: 0.092 and parameters:
\{'lr': 0.01008819509715368, 'weight\_decay': 6.156035815462389e-05, 'momentum':
0.5108930572112749\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:52,795] Trial 14 finished with value: 0.084 and parameters:
\{'lr': 0.002498175105308497, 'weight\_decay': 5.0457871802685105e-05, 'momentum':
0.1687453843903708\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:54,429] Trial 15 finished with value: 0.144 and parameters:
\{'lr': 0.08899241419385215, 'weight\_decay': 0.0024542995513446913, 'momentum':
0.4625382849823203\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:56,033] Trial 16 finished with value: 0.102 and parameters:
\{'lr': 0.08302048956120808, 'weight\_decay': 0.002112499752842944, 'momentum':
0.5198272525214307\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:57,648] Trial 17 finished with value: 0.138 and parameters:
\{'lr': 0.032588654888491546, 'weight\_decay': 0.0038768731862778654, 'momentum':
0.4550066027690283\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:59,361] Trial 18 finished with value: 0.124 and parameters:
\{'lr': 0.04967893602111068, 'weight\_decay': 0.00087695279443526, 'momentum':
0.6205566987029656\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:02:01,135] Trial 19 finished with value: 0.144 and parameters:
\{'lr': 0.014931709180985353, 'weight\_decay': 0.0004543863409564157, 'momentum':
0.4339534081173413\}. Best is trial 15 with value: 0.144.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
ğğğ
Mejores hiperparÃ¡metros: \{'lr': 0.08899241419385215, 'weight\_decay':
0.0024542995513446913, 'momentum': 0.4625382849823203\}
Mejor valor objetivo: 0.144
    \end{Verbatim}

    Los resultados que estamos obteniendo son un poco bajos para el conjunto
de datos CIFAR-10, aunque se debe considerar que hemos reducido
significativamente la complejidad del modelo y el tamaÃ±o del subconjunto
de datos.

Ahora modificaremos el codigo un poco, el cual incrementa el nÃºmero de
Ã©pocas y usa un subconjunto de datos mÃ¡s grande:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{transforms} \PY{k}{as} \PY{n+nn}{transforms}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{as} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}

\PY{c+c1}{\PYZsh{} Definimos un modelo VGG simplificado}
\PY{k}{class} \PY{n+nc}{SimpleVGG}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{SimpleVGG}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128} \PY{o}{*} \PY{l+m+mi}{4} \PY{o}{*} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{)}
        \PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Definimos la funciÃ³n objetivo para optimizar con Optuna}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Cargamos un subconjunto del dataset CIFAR10}
    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}train} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}test} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Usamos un subconjunto mÃ¡s pequeÃ±o del dataset}
    \PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{5000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{5000}\PY{p}{]}\PY{p}{)}
    \PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}

    \PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{testloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos los hiperparÃ¡metros a optimizar}
    \PY{n}{lr} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{weight\PYZus{}decay} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{momentum} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{momentum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos el modelo, el optimizador y la funciÃ³n de pÃ©rdida}
    \PY{n}{model} \PY{o}{=} \PY{n}{SimpleVGG}\PY{p}{(}\PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
    \PY{n}{optimizer} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{SGD}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{,} \PY{n}{momentum}\PY{o}{=}\PY{n}{momentum}\PY{p}{,} \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{weight\PYZus{}decay}\PY{p}{)}
    \PY{n}{loss\PYZus{}fn} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Entrenamos el modelo por 5 Ã©pocas}
    \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}  \PY{c+c1}{\PYZsh{} Incrementa el nÃºmero de Ã©pocas}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{trainloader}\PY{p}{:}
            \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fn}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{target}\PY{p}{)}
            \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
            \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Evaluamos el modelo en el conjunto de prueba}
    \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
    \PY{n}{correct} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{testloader}\PY{p}{:}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{pred} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keepdim}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            \PY{n}{correct} \PY{o}{+}\PY{o}{=} \PY{n}{pred}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{target}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{pred}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Calculamos la precisiÃ³n en el conjunto de prueba y devolverla como el valor objetivo para Optuna}
    \PY{n}{accuracy} \PY{o}{=} \PY{n}{correct} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{testloader}\PY{o}{.}\PY{n}{dataset}\PY{p}{)}
    \PY{k}{return} \PY{n}{accuracy}

\PY{c+c1}{\PYZsh{} Ejecutamos el estudio de Optuna para optimizar los hiperparÃ¡metros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{maximize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}  \PY{c+c1}{\PYZsh{} NÃºmero reducido de pruebas por simplicidad}

\PY{c+c1}{\PYZsh{} Imprimimos los mejores hiperparÃ¡metros y el mejor valor objetivo encontrado por Optuna}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores hiperparÃ¡metros: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor objetivo: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 07:02:40,477] A new study created in memory with name: no-
name-f314dfe2-7380-41db-b47b-6540247e8175
[I 2024-06-20 07:02:53,819] Trial 0 finished with value: 0.198 and parameters:
\{'lr': 0.00845991323388558, 'weight\_decay': 4.05249623080612e-05, 'momentum':
0.21636263055137983\}. Best is trial 0 with value: 0.198.
[I 2024-06-20 07:03:06,944] Trial 1 finished with value: 0.185 and parameters:
\{'lr': 0.04328877533411029, 'weight\_decay': 0.0032581492626639567, 'momentum':
0.1560813751939938\}. Best is trial 0 with value: 0.198.
[I 2024-06-20 07:03:20,391] Trial 2 finished with value: 0.263 and parameters:
\{'lr': 0.018164393518388437, 'weight\_decay': 0.012957315385372072, 'momentum':
0.8973338245769505\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:33,203] Trial 3 finished with value: 0.234 and parameters:
\{'lr': 0.001902261227532657, 'weight\_decay': 0.022056829136624552, 'momentum':
0.9881619924809797\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:46,146] Trial 4 finished with value: 0.137 and parameters:
\{'lr': 0.06700217000901784, 'weight\_decay': 0.00090189347600982, 'momentum':
0.19922116435475745\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:58,859] Trial 5 finished with value: 0.206 and parameters:
\{'lr': 0.04789214649477456, 'weight\_decay': 0.027853106740298263, 'momentum':
0.41128392428611493\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:04:11,669] Trial 6 finished with value: 0.13 and parameters:
\{'lr': 0.0009580519917326726, 'weight\_decay': 0.008775747071715556, 'momentum':
0.8396640451886481\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:04:24,490] Trial 7 finished with value: 0.324 and parameters:
\{'lr': 0.06720776167555383, 'weight\_decay': 4.374825826675419e-05, 'momentum':
0.47966590440850343\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:04:36,882] Trial 8 finished with value: 0.107 and parameters:
\{'lr': 0.00288843840907154, 'weight\_decay': 0.0009721946398552832, 'momentum':
0.630922915233342\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:04:49,500] Trial 9 finished with value: 0.182 and parameters:
\{'lr': 0.021963597743462432, 'weight\_decay': 3.395403242544441e-05, 'momentum':
0.3876345278931973\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:03,185] Trial 10 finished with value: 0.124 and parameters:
\{'lr': 0.00010111637111118573, 'weight\_decay': 0.00018394766078888146,
'momentum': 0.6681767071833634\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:16,363] Trial 11 finished with value: 0.103 and parameters:
\{'lr': 0.010776510243293905, 'weight\_decay': 0.08247868750605579, 'momentum':
0.6599817795221479\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:29,278] Trial 12 finished with value: 0.098 and parameters:
\{'lr': 0.01223479007366479, 'weight\_decay': 1.1251620275673595e-05, 'momentum':
0.006142325466191978\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:41,783] Trial 13 finished with value: 0.09 and parameters:
\{'lr': 0.07694733849216753, 'weight\_decay': 0.0003343764676150295, 'momentum':
0.9945025204177538\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:54,433] Trial 14 finished with value: 0.248 and parameters:
\{'lr': 0.02300989668399209, 'weight\_decay': 0.005728819055967981, 'momentum':
0.5187607769567051\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:06,896] Trial 15 finished with value: 0.147 and parameters:
\{'lr': 0.0004412467845433172, 'weight\_decay': 0.00013059446951642492,
'momentum': 0.8100683966639503\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:20,110] Trial 16 finished with value: 0.145 and parameters:
\{'lr': 0.005218416684973856, 'weight\_decay': 0.00206167401248512, 'momentum':
0.5089084607879426\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:32,850] Trial 17 finished with value: 0.398 and parameters:
\{'lr': 0.0237744576848544, 'weight\_decay': 1.3666934273072666e-05, 'momentum':
0.8165255624909171\}. Best is trial 17 with value: 0.398.
[I 2024-06-20 07:06:45,394] Trial 18 finished with value: 0.296 and parameters:
\{'lr': 0.08741406573595607, 'weight\_decay': 1.0086066506405488e-05, 'momentum':
0.752628067119733\}. Best is trial 17 with value: 0.398.
[I 2024-06-20 07:06:58,189] Trial 19 finished with value: 0.252 and parameters:
\{'lr': 0.031138160476250044, 'weight\_decay': 4.335467227065734e-05, 'momentum':
0.3358055693744339\}. Best is trial 17 with value: 0.398.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Mejores hiperparÃ¡metros: \{'lr': 0.0237744576848544, 'weight\_decay':
1.3666934273072666e-05, 'momentum': 0.8165255624909171\}
Mejor valor objetivo: 0.398
    \end{Verbatim}

    \hypertarget{experimentaciuxf3n-con-modelos-secuenciales-para-nlp}{%
\subsection{3. ExperimentaciÃ³n con modelos secuenciales para
NLP:}\label{experimentaciuxf3n-con-modelos-secuenciales-para-nlp}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Aplicar Optuna en modelos LSTM o Transformer para tareas como
  traducciÃ³n automÃ¡tica o generaciÃ³n de texto. \textbackslash{}
\item
  Optimizar hiperparÃ¡metros como el nÃºmero de capas, la dimensiÃ³n de los
  embeddings y los parÃ¡metros especÃ­ficos de atenciÃ³n. \textbackslash{}
\item
  Analizar cÃ³mo la optimizaciÃ³n afecta la calidad del texto generado y
  la velocidad de convergencia.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{datasets}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Requirement already satisfied: datasets in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(2.20.0)
Requirement already satisfied: filelock in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (3.15.3)
Requirement already satisfied: numpy>=1.17 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (2.0.0)
Requirement already satisfied: pyarrow>=15.0.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.3.8)
Requirement already satisfied: pandas in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (2.2.2)
Requirement already satisfied: requests>=2.32.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (2.32.3)
Requirement already satisfied: tqdm>=4.66.3 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (4.66.4)
Requirement already satisfied: xxhash in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (3.4.1)
Requirement already satisfied: multiprocess in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)
Requirement already satisfied: aiohttp in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (3.9.5)
Requirement already satisfied: huggingface-hub>=0.21.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.23.4)
Requirement already satisfied: packaging in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (24.1)
Requirement already satisfied: pyyaml>=5.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (6.0.1)
Requirement already satisfied: aiosignal>=1.1.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.9.4)
Requirement already satisfied: typing-extensions>=3.7.4.3 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from huggingface-hub>=0.21.2->datasets) (4.12.2)
Requirement already satisfied: charset-normalizer<4,>=2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (2024.6.2)
Requirement already satisfied: python-dateutil>=2.8.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2024.1)
Requirement already satisfied: six>=1.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}pip install \PYZhy{}U accelerate }
\PY{c+c1}{\PYZsh{}pip install \PYZhy{}U transformers}
\PY{c+c1}{\PYZsh{}los instale desde la consola}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{load\PYZus{}dataset}
\PY{k+kn}{from} \PY{n+nn}{transformers} \PY{k+kn}{import} \PY{p}{(}
    \PY{n}{AutoTokenizer}\PY{p}{,}
    \PY{n}{AutoModelForSequenceClassification}\PY{p}{,}
    \PY{n}{TrainingArguments}\PY{p}{,}
    \PY{n}{Trainer}\PY{p}{,}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} Cargar dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZus{}corpus\PYZus{}v2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ade\PYZus{}corpus\PYZus{}v2\PYZus{}classification}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Definir el nombre del modelo y tokenizer}
\PY{n}{model\PYZus{}name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bert\PYZhy{}base\PYZhy{}uncased}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{tokenizer} \PY{o}{=} \PY{n}{AutoTokenizer}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}

\PY{c+c1}{\PYZsh{} FunciÃ³n de preprocesamiento}
\PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{examples}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{tokenizer}\PY{p}{(}
        \PY{n}{examples}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{text}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{truncation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}length}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{64}
    \PY{p}{)}

\PY{c+c1}{\PYZsh{} Preprocesar el dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} FunciÃ³n objetivo para optimizaciÃ³n de hiperparÃ¡metros}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{:} \PY{n}{optuna}\PY{o}{.}\PY{n}{Trial}\PY{p}{)}\PY{p}{:}
    \PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}
    \PY{n}{output\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZhy{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{trial\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Directorio de salida Ãºnico para cada ensayo}
    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{output\PYZus{}dir}\PY{p}{,} \PY{n}{exist\PYZus{}ok}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

    \PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
        \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{,}
        \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{,}
        \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
        \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
        \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
        \PY{n}{evaluation\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Evaluar al final de cada Ã©poca}
        \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}         \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
        \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 100 pasos}
        \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
        \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
        \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
        \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
        \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{result} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{result}\PY{o}{.}\PY{n}{training\PYZus{}loss}

\PY{c+c1}{\PYZsh{} Optimizar hiperparÃ¡metros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{study\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hyper\PYZhy{}parameter\PYZhy{}search}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{minimize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Reducir el nÃºmero de trials}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor de pÃ©rdida:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores parÃ¡metros:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor trial:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
Downloading readme: 100\%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââ
ââââââââââââââââââââ| 10.2k/10.2k [00:00<00:00, 10.8MB/s]
Downloading data: 100\%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
ââââââââââââââââââââ| 1.71M/1.71M [00:01<00:00, 1.06MB/s]
Generating train split:
100\%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 23516/23516
[00:00<00:00, 801303.53 examples/s]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/huggingface\_hub/file\_download.py:1132: FutureWarning: `resume\_download`
is deprecated and will be removed in version 1.0.0. Downloads always resume when
possible. If you want to force a new download, use `force\_download=True`.
  warnings.warn(
Map: 100\%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
âââââââââ| 18812/18812 [00:01<00:00, 15358.57 examples/s]
Map: 100\%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
âââââââââââ| 4704/4704 [00:00<00:00, 17729.88 examples/s]
[I 2024-06-20 07:26:59,629] A new study created in memory with name: hyper-
parameter-search
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
/tmp/ipykernel\_1104303/3918511221.py:37: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  learning\_rate=trial.suggest\_loguniform("learning\_rate", low=4e-5, high=0.01),
/tmp/ipykernel\_1104303/3918511221.py:38: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  weight\_decay=trial.suggest\_loguniform("weight\_decay", 4e-5, 0.01),
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/training\_args.py:1474: FutureWarning:
`evaluation\_strategy` is deprecated and will be removed in version 4.46 of ğ¤
Transformers. Use `eval\_strategy` instead
  warnings.warn(
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'loss': 0.6208, 'grad\_norm': 4.609071254730225, 'learning\_rate':
0.00043125496300916487, 'epoch': 0.08503401360544217\}
\{'loss': 0.6261, 'grad\_norm': 0.8630306124687195, 'learning\_rate':
0.000412105097866662, 'epoch': 0.17006802721088435\}
\{'loss': 0.617, 'grad\_norm': 0.47822126746177673, 'learning\_rate':
0.0003929552327241591, 'epoch': 0.25510204081632654\}
\{'loss': 0.6055, 'grad\_norm': 1.0605601072311401, 'learning\_rate':
0.00037380536758165625, 'epoch': 0.3401360544217687\}
\{'loss': 0.6239, 'grad\_norm': 10.253633499145508, 'learning\_rate':
0.0003546555024391534, 'epoch': 0.42517006802721086\}
\{'loss': 0.6232, 'grad\_norm': 1.439030408859253, 'learning\_rate':
0.0003355056372966505, 'epoch': 0.5102040816326531\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[W 2024-06-20 07:50:13,769] Trial 0 failed with parameters: \{'learning\_rate':
0.00045040482815166775, 'weight\_decay': 0.00025689528868076927,
'num\_train\_epochs': 2\} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/optuna/study/\_optimize.py", line 196, in \_run\_trial
    value\_or\_values = func(trial)
                      \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/tmp/ipykernel\_1104303/3918511221.py", line 53, in objective
    result = trainer.train()
             \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 1885, in train
    return inner\_training\_loop(
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 2216, in \_inner\_training\_loop
    tr\_loss\_step = self.training\_step(model, inputs)
                   \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 3238, in training\_step
    loss = self.compute\_loss(model, inputs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 3264, in compute\_loss
    outputs = model(**inputs)
              \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 1691, in forward
    outputs = self.bert(
              \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 1137, in forward
    encoder\_outputs = self.encoder(
                      \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 690, in forward
    layer\_outputs = layer\_module(
                    \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 580, in forward
    self\_attention\_outputs = self.attention(
                             \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 519, in forward
    attention\_output = self.output(self\_outputs[0], hidden\_states)
                       \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 461, in forward
    hidden\_states = self.dense(hidden\_states)
                    \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
KeyboardInterrupt
[W 2024-06-20 07:50:13,775] Trial 0 failed with value None.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}, frame=single, framerule=2mm, rulecolor=\color{outerrorbackground}]
\textcolor{ansi-red}{---------------------------------------------------------------------------}
\textcolor{ansi-red}{KeyboardInterrupt}                         Traceback (most recent call last)
Cell \textcolor{ansi-green}{In[4], line 58}
\textcolor{ansi-green-intense}{\textbf{     56}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Optimizar hiperparÃ¡metros}
\textcolor{ansi-green-intense}{\textbf{     57}} study \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} optuna\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}create\_study(study\_name\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{hyper-parameter-search}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, direction\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{minimize}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"})
\textcolor{ansi-green}{---> 58} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{optimize\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{objective\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{5\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Reducir el nÃºmero de trials}
\textcolor{ansi-green-intense}{\textbf{     60}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{print}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Mejor valor de pÃ©rdida:}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}best\_value)
\textcolor{ansi-green-intense}{\textbf{     61}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{print}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Mejores parÃ¡metros:}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}best\_params)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/study.py:451}, in \textcolor{ansi-cyan}{Study.optimize}\textcolor{ansi-blue}{(self, func, n\_trials, timeout, n\_jobs, catch, callbacks, gc\_after\_trial, show\_progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{    348}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{optimize}(
\textcolor{ansi-green-intense}{\textbf{    349}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    350}}     func: ObjectiveFuncType,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    357}}     show\_progress\_bar: \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{bool} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}},
\textcolor{ansi-green-intense}{\textbf{    358}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}:
\textcolor{ansi-green-intense}{\textbf{    359}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{188,188,188}}{    }\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""Optimize an objective function.}
\textcolor{ansi-green-intense}{\textbf{    360}} 
\textcolor{ansi-green-intense}{\textbf{    361}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    Optimization is done by choosing a suitable set of hyperparameter values from a given}
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    449}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{            If nested invocation of this method occurs.}
\textcolor{ansi-green-intense}{\textbf{    450}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    """}
\textcolor{ansi-green}{--> 451}     \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_optimize\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    452}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    453}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    454}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    455}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    456}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_jobs\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_jobs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    457}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{tuple\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{if}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{isinstance\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{Iterable\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{else}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    458}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    459}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    460}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{show\_progress\_bar\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{show\_progress\_bar\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    461}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:62}, in \textcolor{ansi-cyan}{\_optimize}\textcolor{ansi-blue}{(study, func, n\_trials, timeout, n\_jobs, catch, callbacks, gc\_after\_trial, show\_progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{     60}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{     61}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} n\_jobs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:
\textcolor{ansi-green}{---> 62}         \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_optimize\_sequential\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{     63}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     64}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     65}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     66}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     67}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     68}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     69}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     70}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{reseed\_sampler\_rng\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{False}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     71}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{time\_start\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{None}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     72}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{progress\_bar\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{progress\_bar\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     73}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{     74}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green-intense}{\textbf{     75}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} n\_jobs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:159}, in \textcolor{ansi-cyan}{\_optimize\_sequential}\textcolor{ansi-blue}{(study, func, n\_trials, timeout, catch, callbacks, gc\_after\_trial, reseed\_sampler\_rng, time\_start, progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{    156}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{break}}
\textcolor{ansi-green-intense}{\textbf{    158}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green}{--> 159}     frozen\_trial \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_run\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    160}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{finally}}:
\textcolor{ansi-green-intense}{\textbf{    161}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# The following line mitigates memory problems that can be occurred in some}
\textcolor{ansi-green-intense}{\textbf{    162}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# environments (e.g., services that use computing containers such as GitHub Actions).}
\textcolor{ansi-green-intense}{\textbf{    163}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Please refer to the following PR for further details:}
\textcolor{ansi-green-intense}{\textbf{    164}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# https://github.com/optuna/optuna/pull/325.}
\textcolor{ansi-green-intense}{\textbf{    165}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} gc\_after\_trial:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:247}, in \textcolor{ansi-cyan}{\_run\_trial}\textcolor{ansi-blue}{(study, func, catch)}
\textcolor{ansi-green-intense}{\textbf{    240}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{assert}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Should not reach.}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}
\textcolor{ansi-green-intense}{\textbf{    242}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} (
\textcolor{ansi-green-intense}{\textbf{    243}}     frozen\_trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} TrialState\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}FAIL
\textcolor{ansi-green-intense}{\textbf{    244}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} func\_err \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green-intense}{\textbf{    245}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{isinstance}(func\_err, catch)
\textcolor{ansi-green-intense}{\textbf{    246}} ):
\textcolor{ansi-green}{--> 247}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{raise}} func\_err
\textcolor{ansi-green-intense}{\textbf{    248}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} frozen\_trial

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:196}, in \textcolor{ansi-cyan}{\_run\_trial}\textcolor{ansi-blue}{(study, func, catch)}
\textcolor{ansi-green-intense}{\textbf{    194}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} get\_heartbeat\_thread(trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_trial\_id, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_storage):
\textcolor{ansi-green-intense}{\textbf{    195}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green}{--> 196}         value\_or\_values \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    197}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{except}} exceptions\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}TrialPruned \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{as}} e:
\textcolor{ansi-green-intense}{\textbf{    198}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# TODO(mamu): Handle multi-objective cases.}
\textcolor{ansi-green-intense}{\textbf{    199}}         state \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} TrialState\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}PRUNED

Cell \textcolor{ansi-green}{In[4], line 53}, in \textcolor{ansi-cyan}{objective}\textcolor{ansi-blue}{(trial)}
\textcolor{ansi-green-intense}{\textbf{     35}} training\_args \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} TrainingArguments(
\textcolor{ansi-green-intense}{\textbf{     36}}     output\_dir\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}output\_dir,
\textcolor{ansi-green-intense}{\textbf{     37}}     learning\_rate\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}suggest\_loguniform(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{learning\_rate}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, low\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{4e-5}, high\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0.01}),
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{     45}}     disable\_tqdm\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{True}},
\textcolor{ansi-green-intense}{\textbf{     46}} )
\textcolor{ansi-green-intense}{\textbf{     47}} trainer \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} Trainer(
\textcolor{ansi-green-intense}{\textbf{     48}}     model\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}model,
\textcolor{ansi-green-intense}{\textbf{     49}}     args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}training\_args,
\textcolor{ansi-green-intense}{\textbf{     50}}     train\_dataset\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}dataset[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{train}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}],
\textcolor{ansi-green-intense}{\textbf{     51}}     eval\_dataset\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}dataset[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{test}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}],
\textcolor{ansi-green-intense}{\textbf{     52}} )
\textcolor{ansi-green}{---> 53} result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trainer\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{train\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{     54}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} result\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}training\_loss

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:1885}, in \textcolor{ansi-cyan}{Trainer.train}\textcolor{ansi-blue}{(self, resume\_from\_checkpoint, trial, ignore\_keys\_for\_eval, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1883}}         hf\_hub\_utils\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}enable\_progress\_bars()
\textcolor{ansi-green-intense}{\textbf{   1884}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1885}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inner\_training\_loop\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1886}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1887}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{resume\_from\_checkpoint\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{resume\_from\_checkpoint\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1888}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1889}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ignore\_keys\_for\_eval\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ignore\_keys\_for\_eval\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1890}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:2216}, in \textcolor{ansi-cyan}{Trainer.\_inner\_training\_loop}\textcolor{ansi-blue}{(self, batch\_size, args, resume\_from\_checkpoint, trial, ignore\_keys\_for\_eval)}
\textcolor{ansi-green-intense}{\textbf{   2213}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}control \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}callback\_handler\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}on\_step\_begin(args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}control)
\textcolor{ansi-green-intense}{\textbf{   2215}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}accelerator\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}accumulate(model):
\textcolor{ansi-green}{-> 2216}     tr\_loss\_step \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{training\_step\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   2218}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} (
\textcolor{ansi-green-intense}{\textbf{   2219}}     args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}logging\_nan\_inf\_filter
\textcolor{ansi-green-intense}{\textbf{   2220}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} is\_torch\_xla\_available()
\textcolor{ansi-green-intense}{\textbf{   2221}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} (torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}isnan(tr\_loss\_step) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}isinf(tr\_loss\_step))
\textcolor{ansi-green-intense}{\textbf{   2222}} ):
\textcolor{ansi-green-intense}{\textbf{   2223}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# if loss is nan or inf simply add the average of previous logged losses}
\textcolor{ansi-green-intense}{\textbf{   2224}}     tr\_loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} tr\_loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{/} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}global\_step \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_globalstep\_last\_logged)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:3238}, in \textcolor{ansi-cyan}{Trainer.training\_step}\textcolor{ansi-blue}{(self, model, inputs)}
\textcolor{ansi-green-intense}{\textbf{   3235}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} loss\_mb\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}reduce\_mean()\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}detach()\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}to(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}device)
\textcolor{ansi-green-intense}{\textbf{   3237}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}compute\_loss\_context\_manager():
\textcolor{ansi-green}{-> 3238}     loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{compute\_loss\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   3240}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{del}} inputs
\textcolor{ansi-green-intense}{\textbf{   3241}} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}cuda\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}empty\_cache()

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:3264}, in \textcolor{ansi-cyan}{Trainer.compute\_loss}\textcolor{ansi-blue}{(self, model, inputs, return\_outputs)}
\textcolor{ansi-green-intense}{\textbf{   3262}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green-intense}{\textbf{   3263}}     labels \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green}{-> 3264} outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   3265}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Save past state if it exists}
\textcolor{ansi-green-intense}{\textbf{   3266}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# TODO: this needs to be fixed and made cleaner later.}
\textcolor{ansi-green-intense}{\textbf{   3267}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}past\_index \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:1691}, in \textcolor{ansi-cyan}{BertForSequenceClassification.forward}\textcolor{ansi-blue}{(self, input\_ids, attention\_mask, token\_type\_ids, position\_ids, head\_mask, inputs\_embeds, labels, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{   1683}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{r}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green-intense}{\textbf{   1684}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{labels (`torch.LongTensor` of shape `(batch\_size,)`, *optional*):}
\textcolor{ansi-green-intense}{\textbf{   1685}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    Labels for computing the sequence classification/regression loss. Indices should be in `[0, {\ldots},}
\textcolor{ansi-green-intense}{\textbf{   1686}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    config.num\_labels - 1]`. If `config.num\_labels == 1` a regression loss is computed (Mean-Square loss), If}
\textcolor{ansi-green-intense}{\textbf{   1687}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    `config.num\_labels > 1` a classification loss is computed (Cross-Entropy).}
\textcolor{ansi-green-intense}{\textbf{   1688}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green-intense}{\textbf{   1689}} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}config\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}use\_return\_dict
\textcolor{ansi-green}{-> 1691} outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{bert\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1692}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{input\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1693}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1694}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{token\_type\_ids\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{token\_type\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1695}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{position\_ids\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{position\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1696}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1697}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\_embeds\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\_embeds\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1698}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1699}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1700}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1701}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1703}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}]
\textcolor{ansi-green-intense}{\textbf{   1705}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}dropout(pooled\_output)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:1137}, in \textcolor{ansi-cyan}{BertModel.forward}\textcolor{ansi-blue}{(self, input\_ids, attention\_mask, token\_type\_ids, position\_ids, head\_mask, inputs\_embeds, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_values, use\_cache, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{   1130}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Prepare head mask if needed}
\textcolor{ansi-green-intense}{\textbf{   1131}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# 1.0 in head\_mask indicate we keep the head}
\textcolor{ansi-green-intense}{\textbf{   1132}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# attention\_probs has shape bsz x n\_heads x N x N}
\textcolor{ansi-green-intense}{\textbf{   1133}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# input head\_mask has shape [num\_heads] or [num\_hidden\_layers x num\_heads]}
\textcolor{ansi-green-intense}{\textbf{   1134}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# and head\_mask is converted to shape [num\_hidden\_layers x batch x num\_heads x seq\_length x seq\_length]}
\textcolor{ansi-green-intense}{\textbf{   1135}} head\_mask \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}get\_head\_mask(head\_mask, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}config\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}num\_hidden\_layers)
\textcolor{ansi-green}{-> 1137} encoder\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1138}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{embedding\_output\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1139}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{extended\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1140}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1141}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1142}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_extended\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1143}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_values\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_values\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1144}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{use\_cache\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{use\_cache\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1145}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1146}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1147}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1148}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1149}} sequence\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} encoder\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{   1150}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}pooler(sequence\_output) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}pooler \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:690}, in \textcolor{ansi-cyan}{BertEncoder.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_values, use\_cache, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{    679}}     layer\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_gradient\_checkpointing\_func(
\textcolor{ansi-green-intense}{\textbf{    680}}         layer\_module\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\_\_call\_\_},
\textcolor{ansi-green-intense}{\textbf{    681}}         hidden\_states,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    687}}         output\_attentions,
\textcolor{ansi-green-intense}{\textbf{    688}}     )
\textcolor{ansi-green-intense}{\textbf{    689}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{--> 690}     layer\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{layer\_module\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    691}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    692}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    693}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{layer\_head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    694}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    695}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    696}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_value\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    697}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    698}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    700}} hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} layer\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{    701}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} use\_cache:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:580}, in \textcolor{ansi-cyan}{BertLayer.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_value, output\_attentions)}
\textcolor{ansi-green-intense}{\textbf{    568}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(
\textcolor{ansi-green-intense}{\textbf{    569}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    570}}     hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    577}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tuple[torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor]:
\textcolor{ansi-green-intense}{\textbf{    578}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# decoder uni-directional self-attention cached key/values tuple is at positions 1,2}
\textcolor{ansi-green-intense}{\textbf{    579}}     self\_attn\_past\_key\_value \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} past\_key\_value[:\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{2}] \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} past\_key\_value \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green}{--> 580}     self\_attention\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    581}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    582}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    583}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    584}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    585}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_value\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\_attn\_past\_key\_value\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    586}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    587}}     attention\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} self\_attention\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{    589}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# if decoder, the last output is tuple of self-attn cache}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:519}, in \textcolor{ansi-cyan}{BertAttention.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_value, output\_attentions)}
\textcolor{ansi-green-intense}{\textbf{    500}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(
\textcolor{ansi-green-intense}{\textbf{    501}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    502}}     hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    508}}     output\_attentions: Optional[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{bool}] \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}},
\textcolor{ansi-green-intense}{\textbf{    509}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tuple[torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor]:
\textcolor{ansi-green-intense}{\textbf{    510}}     self\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}self(
\textcolor{ansi-green-intense}{\textbf{    511}}         hidden\_states,
\textcolor{ansi-green-intense}{\textbf{    512}}         attention\_mask,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    517}}         output\_attentions,
\textcolor{ansi-green-intense}{\textbf{    518}}     )
\textcolor{ansi-green}{--> 519}     attention\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\_outputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{[\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{0\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{]\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    520}}     outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} (attention\_output,) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} self\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:]  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# add attentions if we output them}
\textcolor{ansi-green-intense}{\textbf{    521}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} outputs

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:461}, in \textcolor{ansi-cyan}{BertSelfOutput.forward}\textcolor{ansi-blue}{(self, hidden\_states, input\_tensor)}
\textcolor{ansi-green-intense}{\textbf{    460}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}, hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor, input\_tensor: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor:
\textcolor{ansi-green}{--> 461}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{dense\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    462}}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}dropout(hidden\_states)
\textcolor{ansi-green-intense}{\textbf{    463}}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}LayerNorm(hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} input\_tensor)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/linear.py:116}, in \textcolor{ansi-cyan}{Linear.forward}\textcolor{ansi-blue}{(self, input)}
\textcolor{ansi-green-intense}{\textbf{    115}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{input}: Tensor) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tensor:
\textcolor{ansi-green}{--> 116}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{F\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{linear\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{input\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{weight\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{bias\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

\textcolor{ansi-red}{KeyboardInterrupt}: 
    \end{Verbatim}

    En esta versiÃ³n del cÃ³digo, se han realizado varias modificaciones para
mejorar la eficiencia y resolver advertencias. Estas incluyen la
actualizaciÃ³n del mÃ©todo de sugerencia de hiperparÃ¡metros
suggest\_loguniform a suggest\_float con log=True, la correcciÃ³n de
evaluation\_strategy a eval\_strategy, la desactivaciÃ³n de tqdm para
reducir el tiempo de registro, y la gestiÃ³n adecuada de pesos no
inicializados. AdemÃ¡s, se ha reducido el tamaÃ±o del dataset para los
ensayos iniciales y se asegura el uso de GPU si estÃ¡ disponible, lo que
contribuye a una ejecuciÃ³n mÃ¡s rÃ¡pida y eficiente.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{load\PYZus{}dataset}
\PY{k+kn}{from} \PY{n+nn}{transformers} \PY{k+kn}{import} \PY{p}{(}
    \PY{n}{AutoTokenizer}\PY{p}{,}
    \PY{n}{AutoModelForSequenceClassification}\PY{p}{,}
    \PY{n}{TrainingArguments}\PY{p}{,}
    \PY{n}{Trainer}\PY{p}{,}
\PY{p}{)}
\PY{k+kn}{import} \PY{n+nn}{torch}

\PY{c+c1}{\PYZsh{} Usar GPU si estÃ¡ disponible}
\PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Cargar dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZus{}corpus\PYZus{}v2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ade\PYZus{}corpus\PYZus{}v2\PYZus{}classification}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Reducir aÃºn mÃ¡s el tamaÃ±o del dataset para ensayos iniciales}
\PY{n}{small\PYZus{}train\PYZus{}dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{)}\PY{p}{)}
\PY{n}{small\PYZus{}eval\PYZus{}dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Definir el nombre del modelo y tokenizer}
\PY{n}{model\PYZus{}name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bert\PYZhy{}base\PYZhy{}uncased}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{tokenizer} \PY{o}{=} \PY{n}{AutoTokenizer}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}

\PY{c+c1}{\PYZsh{} FunciÃ³n de preprocesamiento}
\PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{examples}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{tokenizer}\PY{p}{(}
        \PY{n}{examples}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{text}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{truncation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}length}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{64}
    \PY{p}{)}

\PY{c+c1}{\PYZsh{} Preprocesar el dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\PY{n}{small\PYZus{}train\PYZus{}dataset} \PY{o}{=} \PY{n}{small\PYZus{}train\PYZus{}dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\PY{n}{small\PYZus{}eval\PYZus{}dataset} \PY{o}{=} \PY{n}{small\PYZus{}eval\PYZus{}dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} FunciÃ³n objetivo para optimizaciÃ³n de hiperparÃ¡metros}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{:} \PY{n}{optuna}\PY{o}{.}\PY{n}{Trial}\PY{p}{)}\PY{p}{:}
    \PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    \PY{n}{output\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZhy{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{trial\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Directorio de salida Ãºnico para cada ensayo}
    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{output\PYZus{}dir}\PY{p}{,} \PY{n}{exist\PYZus{}ok}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

    \PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
        \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
        \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
        \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Reducir el mÃ¡ximo a 3 Ã©pocas}
        \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
        \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
        \PY{n}{eval\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}           \PY{c+c1}{\PYZsh{} Evaluar al final de cada Ã©poca}
        \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}          \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
        \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{500}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 500 pasos}
        \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
        \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
        \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
        \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{small\PYZus{}train\PYZus{}dataset}\PY{p}{,}
        \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{small\PYZus{}eval\PYZus{}dataset}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{result} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{result}\PY{o}{.}\PY{n}{training\PYZus{}loss}

\PY{c+c1}{\PYZsh{} Optimizar hiperparÃ¡metros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{study\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hyper\PYZhy{}parameter\PYZhy{}search}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{minimize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Reducir el nÃºmero de trials a 3}

\PY{c+c1}{\PYZsh{} Entrenar con el mejor conjunto de hiperparÃ¡metros}
\PY{n}{best\PYZus{}trial} \PY{o}{=} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}
\PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
\PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
    \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{final\PYZhy{}model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
    \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaÃ±o de lote}
    \PY{n}{eval\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}           \PY{c+c1}{\PYZsh{} Evaluar al final de cada Ã©poca}
    \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{final\PYZhy{}model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}       \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
    \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{500}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 500 pasos}
    \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
\PY{p}{)}
\PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
    \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
    \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
    \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
\PY{p}{)}
\PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor de pÃ©rdida:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores parÃ¡metros:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor trial:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Map: 100\%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
âââââââââââ| 4704/4704 [00:00<00:00, 16241.83 examples/s]
Map: 100\%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
âââââââââââââ| 500/500 [00:00<00:00, 17101.18 examples/s]
Map: 100\%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
ââââââââââââââ| 100/100 [00:00<00:00, 8745.60 examples/s]
[I 2024-06-20 08:00:15,228] A new study created in memory with name: hyper-
parameter-search
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:01:19,538] Trial 0 finished with value: 0.6301901340484619 and
parameters: \{'learning\_rate': 0.0013548425105920966, 'weight\_decay':
0.000844581377013946, 'num\_train\_epochs': 1\}. Best is trial 0 with value:
0.6301901340484619.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.724229097366333, 'eval\_runtime': 2.8348,
'eval\_samples\_per\_second': 35.276, 'eval\_steps\_per\_second': 2.469, 'epoch': 1.0\}
\{'train\_runtime': 63.5725, 'train\_samples\_per\_second': 7.865,
'train\_steps\_per\_second': 0.503, 'train\_loss': 0.6301901340484619, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:02:23,023] Trial 1 finished with value: 0.760809600353241 and
parameters: \{'learning\_rate': 0.001476016748798422, 'weight\_decay':
0.00367499601830561, 'num\_train\_epochs': 1\}. Best is trial 0 with value:
0.6301901340484619.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.6591594219207764, 'eval\_runtime': 2.8204,
'eval\_samples\_per\_second': 35.456, 'eval\_steps\_per\_second': 2.482, 'epoch': 1.0\}
\{'train\_runtime': 62.9091, 'train\_samples\_per\_second': 7.948,
'train\_steps\_per\_second': 0.509, 'train\_loss': 0.760809600353241, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:03:28,469] Trial 2 finished with value: 0.5697887539863586 and
parameters: \{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}. Best is trial 2 with value:
0.5697887539863586.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.4735482335090637, 'eval\_runtime': 2.8675,
'eval\_samples\_per\_second': 34.874, 'eval\_steps\_per\_second': 2.441, 'epoch': 1.0\}
\{'train\_runtime': 64.712, 'train\_samples\_per\_second': 7.727,
'train\_steps\_per\_second': 0.494, 'train\_loss': 0.5697887539863586, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'loss': 0.615, 'grad\_norm': 0.9341108202934265, 'learning\_rate':
0.0001298759888794938, 'epoch': 0.42517006802721086\}
\{'loss': 0.6097, 'grad\_norm': 2.0760040283203125, 'learning\_rate':
3.381386692720549e-05, 'epoch': 0.8503401360544217\}
\{'eval\_loss': 0.5997103452682495, 'eval\_runtime': 151.5124,
'eval\_samples\_per\_second': 31.047, 'eval\_steps\_per\_second': 1.94, 'epoch': 1.0\}
\{'train\_runtime': 2566.1987, 'train\_samples\_per\_second': 7.331,
'train\_steps\_per\_second': 0.458, 'train\_loss': 0.609258729584363, 'epoch': 1.0\}
Mejor valor de pÃ©rdida: 0.5697887539863586
Mejores parÃ¡metros: \{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}
Mejor trial: FrozenTrial(number=2, state=1, values=[0.5697887539863586],
datetime\_start=datetime.datetime(2024, 6, 20, 8, 2, 23, 24407),
datetime\_complete=datetime.datetime(2024, 6, 20, 8, 3, 28, 469023),
params=\{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}, user\_attrs=\{\}, system\_attrs=\{\},
intermediate\_values=\{\}, distributions=\{'learning\_rate':
FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'weight\_decay':
FloatDistribution(high=0.01, log=True, low=4e-05, step=None),
'num\_train\_epochs': IntDistribution(high=3, log=False, low=1, step=1)\},
trial\_id=2, value=None)
    \end{Verbatim}

    \hypertarget{desarrollo-de-un-sistema-de-prunning-automuxe1tico}{%
\subsection{4. Desarrollo de un sistema de prunning
automÃ¡tico:}\label{desarrollo-de-un-sistema-de-prunning-automuxe1tico}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Implementar y configurar el prunning de ensayos en Optuna para detener
  automÃ¡ticamente los ensayos menos prometedores y reducir el tiempo de
  computaciÃ³n. \textbackslash{}
\item
  Comparar el rendimiento y la eficiencia del proceso de optimizaciÃ³n
  con y sin prunning.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{prune} \PY{k}{as} \PY{n+nn}{prune}

\PY{k}{class} \PY{n+nc}{ModeloPruned}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{PrunedModel}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{784}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Example usage}
\PY{n}{modelo} \PY{o}{=} \PY{n}{ModeloPruned}\PY{p}{(}\PY{p}{)}
\PY{n}{parametros\PYZus{}a\PYZus{}podar} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{n}{modelo}\PY{o}{.}\PY{n}{fc1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{modeloo}\PY{o}{.}\PY{n}{fc2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}
\PY{n}{prune}\PY{o}{.}\PY{n}{global\PYZus{}unstructured}\PY{p}{(}
    \PY{n}{parametros\PYZus{}a\PYZus{}podar}\PY{p}{,}
    \PY{n}{metodo\PYZus{}pruning}\PY{o}{=}\PY{n}{prune}\PY{o}{.}\PY{n}{L1Unstructured}\PY{p}{,}
    \PY{n}{cantidad}\PY{o}{=}\PY{l+m+mf}{0.2}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{integraciuxf3n-de-tuxe9cnicas-de-transfer-learning}{%
\subsection{5. IntegraciÃ³n de tÃ©cnicas de transfer
learning:}\label{integraciuxf3n-de-tuxe9cnicas-de-transfer-learning}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Experimentar con la optimizaciÃ³n de modelos preentrenados en tareas
  especÃ­ficas, ajustando hiperparÃ¡metros para fine-tuning.
  \textbackslash{}
\item
  Evaluar la efectividad de Optuna en la selecciÃ³n de hiperparÃ¡metros
  que maximizan el transfer learning.
\end{enumerate}

    En este ejemplo prÃ¡ctico de optimizaciÃ³n de hiperparÃ¡metros, abordaremos
un problema de clasificaciÃ³n binaria.

(basado en
http://pytorch.org/tutorials/beginner/transfer\_learning\_tutorial.html)

    Utilizaremos el conjunto de datos Hormigas contra Abejas, que forma
parte del conjunto de datos ImageNet. DeberÃ¡ descargarlo desde aquÃ­:
Hormigas contra abejas. Contiene 400 imÃ¡genes, \textasciitilde250 de
entrenamiento y \textasciitilde150 de validaciÃ³n (prueba).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}wget\PY{+w}{ }https://download.pytorch.org/tutorial/hymenoptera\PYZus{}data.zip
\PY{o}{!}unzip\PY{+w}{ }hymenoptera\PYZus{}data.zip
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k+kn}{import} \PY{n}{lr\PYZus{}scheduler}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{backends}\PY{n+nn}{.}\PY{n+nn}{cudnn} \PY{k}{as} \PY{n+nn}{cudnn}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{torchvision}
\PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k+kn}{import} \PY{n}{datasets}\PY{p}{,} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{time}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k+kn}{import} \PY{n}{Image}
\PY{k+kn}{from} \PY{n+nn}{tempfile} \PY{k+kn}{import} \PY{n}{TemporaryDirectory}
\PY{k+kn}{import} \PY{n+nn}{copy}

\PY{n}{cudnn}\PY{o}{.}\PY{n}{benchmark} \PY{o}{=} \PY{k+kc}{True}
\PY{n}{plt}\PY{o}{.}\PY{n}{ion}\PY{p}{(}\PY{p}{)}   \PY{c+c1}{\PYZsh{} interactive mode}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<contextlib.ExitStack at 0x71c9a3111be0>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{data\PYZus{}transforms} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomResizedCrop}\PY{p}{(}\PY{l+m+mi}{224}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomHorizontalFlip}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Normalize}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.485}\PY{p}{,} \PY{l+m+mf}{0.456}\PY{p}{,} \PY{l+m+mf}{0.406}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{0.229}\PY{p}{,} \PY{l+m+mf}{0.224}\PY{p}{,} \PY{l+m+mf}{0.225}\PY{p}{]}\PY{p}{)}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Resize}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{CenterCrop}\PY{p}{(}\PY{l+m+mi}{224}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Normalize}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.485}\PY{p}{,} \PY{l+m+mf}{0.456}\PY{p}{,} \PY{l+m+mf}{0.406}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{0.229}\PY{p}{,} \PY{l+m+mf}{0.224}\PY{p}{,} \PY{l+m+mf}{0.225}\PY{p}{]}\PY{p}{)}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./hymenoptera\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{image\PYZus{}datasets} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{datasets}\PY{o}{.}\PY{n}{ImageFolder}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{,}
                                          \PY{n}{data\PYZus{}transforms}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{)}
                  \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{dataloaders} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}
                                             \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
              \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{dataset\PYZus{}sizes} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{class\PYZus{}names} \PY{o}{=} \PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{classes}

\PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda:0}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    La siguiente funciÃ³n se utilizarÃ¡ para entrenar el modelo:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{train\PYZus{}model}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{criterion}\PY{p}{,} \PY{n}{optimizer}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{since} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}

    \PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{copy}\PY{o}{.}\PY{n}{deepcopy}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{l+m+mf}{0.0}

    \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epoch }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{epoch}\PY{p}{,} \PY{n}{num\PYZus{}epochs} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{*} \PY{l+m+mi}{10}\PY{p}{)}

        \PY{k}{for} \PY{n}{phase} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
            \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)} 
            \PY{k}{else}\PY{p}{:}
                \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}  

            \PY{n}{running\PYZus{}loss} \PY{o}{=} \PY{l+m+mf}{0.0}
            \PY{n}{running\PYZus{}corrects} \PY{o}{=} \PY{l+m+mi}{0}

            \PY{k}{for} \PY{n}{inputs}\PY{p}{,} \PY{n}{labels} \PY{o+ow}{in} \PY{n}{dataloaders}\PY{p}{[}\PY{n}{phase}\PY{p}{]}\PY{p}{:}
                \PY{n}{inputs} \PY{o}{=} \PY{n}{inputs}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
                \PY{n}{labels} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}

                \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}

                \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{set\PYZus{}grad\PYZus{}enabled}\PY{p}{(}\PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{n}{outputs} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}
                    \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{preds} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{outputs}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
                    \PY{n}{loss} \PY{o}{=} \PY{n}{criterion}\PY{p}{(}\PY{n}{outputs}\PY{p}{,} \PY{n}{labels}\PY{p}{)}

                    \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                        \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
                        \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

                \PY{n}{running\PYZus{}loss} \PY{o}{+}\PY{o}{=} \PY{n}{loss}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)} \PY{o}{*} \PY{n}{inputs}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
                \PY{n}{running\PYZus{}corrects} \PY{o}{+}\PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{preds} \PY{o}{==} \PY{n}{labels}\PY{o}{.}\PY{n}{data}\PY{p}{)}

            \PY{n}{epoch\PYZus{}loss} \PY{o}{=} \PY{n}{running\PYZus{}loss} \PY{o}{/} \PY{n}{dataset\PYZus{}sizes}\PY{p}{[}\PY{n}{phase}\PY{p}{]}
            \PY{n}{epoch\PYZus{}acc} \PY{o}{=} \PY{n}{running\PYZus{}corrects}\PY{o}{.}\PY{n}{double}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{dataset\PYZus{}sizes}\PY{p}{[}\PY{n}{phase}\PY{p}{]}

            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ Loss: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{ Acc: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
                \PY{n}{phase}\PY{p}{,} \PY{n}{epoch\PYZus{}loss}\PY{p}{,} \PY{n}{epoch\PYZus{}acc}\PY{p}{)}\PY{p}{)}

            \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{and} \PY{n}{epoch\PYZus{}acc} \PY{o}{\PYZgt{}} \PY{n}{best\PYZus{}acc}\PY{p}{:}
                \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{n}{epoch\PYZus{}acc}
                \PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{copy}\PY{o}{.}\PY{n}{deepcopy}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{)}

        \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{trial}\PY{o}{.}\PY{n}{report}\PY{p}{(}\PY{n}{epoch\PYZus{}acc}\PY{p}{,} \PY{n}{epoch}\PY{p}{)}
        \PY{k}{if} \PY{n}{trial}\PY{o}{.}\PY{n}{should\PYZus{}prune}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{k}{raise} \PY{n}{optuna}\PY{o}{.}\PY{n}{TrialPruned}\PY{p}{(}\PY{p}{)}

    \PY{n}{time\PYZus{}elapsed} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{since}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training complete in }\PY{l+s+si}{\PYZob{}:.0f\PYZcb{}}\PY{l+s+s1}{m }\PY{l+s+si}{\PYZob{}:.0f\PYZcb{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
        \PY{n}{time\PYZus{}elapsed} \PY{o}{/}\PY{o}{/} \PY{l+m+mi}{60}\PY{p}{,} \PY{n}{time\PYZus{}elapsed} \PY{o}{\PYZpc{}} \PY{l+m+mi}{60}\PY{p}{)}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best val Acc: }\PY{l+s+si}{\PYZob{}:4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{best\PYZus{}acc}\PY{p}{)}\PY{p}{)}

    \PY{n}{model}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{best\PYZus{}model\PYZus{}wts}\PY{p}{)}
    \PY{k}{return} \PY{n}{model}\PY{p}{,} \PY{n}{best\PYZus{}acc}
\end{Verbatim}
\end{tcolorbox}

    Para empezar, es fundamental crear la FunciÃ³n Objetivo. Esta funciÃ³n
toma una configuraciÃ³n de hiperparÃ¡metros y devuelve su puntuaciÃ³n de
evaluaciÃ³n (valor objetivo). Optuna resuelve el problema de la
optimizaciÃ³n de hiperparÃ¡metros al maximizar o minimizar esta FunciÃ³n
Objetivo.

La FunciÃ³n Objetivo encapsula el proceso estÃ¡ndar de entrenamiento del
modelo. Definimos nuestro modelo, configuramos optimizadores y funciones
de pÃ©rdida, evaluamos mÃ©tricas, entre otros pasos. En este ejemplo,
evaluaremos la mÃ©trica de precisiÃ³n en el conjunto de validaciÃ³n.
TambiÃ©n devolveremos su valor desde la FunciÃ³n Objetivo para que Optuna
lo utilice en la optimizaciÃ³n.

Dentro de la FunciÃ³n Objetivo, debemos definir los hiperparÃ¡metros que
deseamos optimizar. En Optuna, es posible optimizar diferentes tipos de
hiperparÃ¡metros, como:

\begin{itemize}
\tightlist
\item
  NÃºmeros reales (floats).
\item
  NÃºmeros enteros (integers).
\item
  CategÃ³ricos discretos.
\end{itemize}

    En nuestro ejemplo, optimizaremos tres hiperparÃ¡metros:

\begin{itemize}
\tightlist
\item
  Red preentrenada. Dado que el conjunto de datos de ``Hormigas
  vs.~Abejas'' es pequeÃ±o, utilizaremos transfer learning para obtener
  un modelo de buena calidad. Hemos elegido una de las redes entrenadas
  en ImageNet y reemplazamos las Ãºltimas capas completamente conectadas
  responsables de la clasificaciÃ³n.
\item
  Optimizador: SGD, Adam.
\item
  Tasa de aprendizaje: de 1e-4 a 1e-2.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{objetivo}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    
    \PY{c+c1}{\PYZsh{} HiperparÃ¡metros que queremos optimizar}
    \PY{n}{params} \PY{o}{=} \PY{p}{\PYZob{}}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{alexnet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vgg16}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}2}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{optimizer\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SGD}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{p}{\PYZcb{}}
    
    \PY{c+c1}{\PYZsh{} Obtener el modelo preentrenado}
    \PY{n}{model} \PY{o}{=} \PY{n}{obtener\PYZus{}modelo}\PY{p}{(}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Definir criterio}
    \PY{n}{criterion} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Configurar optimizador}
    \PY{n}{optimizer} \PY{o}{=} \PY{n+nb}{getattr}\PY{p}{(}
        \PY{n}{torch}\PY{o}{.}\PY{n}{optim}\PY{p}{,} \PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{optimizer\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
    \PY{p}{)}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Entrenar el modelo}
    \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{criterion}\PY{p}{,} \PY{n}{optimizer}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Guardar el mejor modelo para cada prueba}
    \PY{c+c1}{\PYZsh{} torch.save(mejor\PYZus{}modelo.state\PYZus{}dict(), f\PYZdq{}modelo\PYZus{}prueba\PYZus{}\PYZob{}prueba.number\PYZcb{}.pth\PYZdq{})}
    
    \PY{c+c1}{\PYZsh{} Devolver precisiÃ³n (Valor Objetivo) de la prueba actual}
    \PY{k}{return} \PY{n}{best\PYZus{}acc}
\end{Verbatim}
\end{tcolorbox}

    Nota: Para obtener un modelo preentrenado por su nombre, aÃ±adiremos una
funciÃ³n get\_model:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{obtener\PYZus{}modelo}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{:} \PY{n+nb}{str} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}  
    \PY{k}{if} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{resnet18}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fc}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{fc} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{elif} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{alexnet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{alexnet}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{classifier}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{elif} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vgg16}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{vgg16}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{classifier}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{return} \PY{n}{model}
\end{Verbatim}
\end{tcolorbox}

    Para empezar a optimizar nuestra FunciÃ³n Objetivo, creamos un nuevo
estudio:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} sampler: queremos usar un muestreador TPE}
\PY{c+c1}{\PYZsh{} pruner: utilizamos MedianPruner para interrumpir pruebas poco prometedoras}
\PY{c+c1}{\PYZsh{} direction: la direcciÃ³n del estudio es \PYZdq{}maximizar\PYZdq{} porque queremos maximizar la precisiÃ³n}
\PY{c+c1}{\PYZsh{} n\PYZus{}trials: NÃºmero de pruebas}

\PY{n}{sampler} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{samplers}\PY{o}{.}\PY{n}{TPESampler}\PY{p}{(}\PY{p}{)}    
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}
    \PY{n}{sampler}\PY{o}{=}\PY{n}{sampler}\PY{p}{,}
    \PY{n}{pruner}\PY{o}{=}\PY{n}{optuna}\PY{o}{.}\PY{n}{pruners}\PY{o}{.}\PY{n}{MedianPruner}\PY{p}{(}
        \PY{n}{n\PYZus{}startup\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{n\PYZus{}warmup\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{interval\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{3}
    \PY{p}{)}\PY{p}{,}
    \PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{maximize}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objetivo}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:24:20,991] A new study created in memory with name: no-
name-9d0d4d94-6f95-41df-860a-24a0b5c9dc69
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 0/4
----------
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1312130/1625103487.py:6: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  "lr": trial.suggest\_loguniform('lr', 1e-4, 1e-2),
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
train Loss: 0.6493 Acc: 0.6393
val Loss: 0.4960 Acc: 0.7843

Epoch 1/4
----------
train Loss: 0.5164 Acc: 0.7582
val Loss: 0.3734 Acc: 0.8693

Epoch 2/4
----------
train Loss: 0.4524 Acc: 0.8033
val Loss: 0.3143 Acc: 0.9150

Epoch 3/4
----------
train Loss: 0.3931 Acc: 0.8484
val Loss: 0.2712 Acc: 0.9020

Epoch 4/4
----------
train Loss: 0.3783 Acc: 0.8197
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:25:33,401] Trial 0 finished with value: 0.934640522875817 and
parameters: \{'model\_name': 'resnet18', 'lr': 0.0008709086527787754,
'optimizer\_name': 'SGD'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.2431 Acc: 0.9346

Training complete in 1m 12s
Best val Acc: 0.934641
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torchvision/models/\_utils.py:223: UserWarning: Arguments other than a
weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed
in the future. The current behavior is equivalent to passing
`weights=VGG16\_Weights.IMAGENET1K\_V1`. You can also use
`weights=VGG16\_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 0/4
----------
train Loss: 790.5330 Acc: 0.4344
val Loss: 8.5681 Acc: 0.4575

Epoch 1/4
----------
train Loss: 1.6542 Acc: 0.5164
val Loss: 0.8113 Acc: 0.5686

Epoch 2/4
----------
train Loss: 0.8495 Acc: 0.4631
val Loss: 0.7626 Acc: 0.5425

Epoch 3/4
----------
train Loss: 0.9628 Acc: 0.4549
val Loss: 0.9402 Acc: 0.4510

Epoch 4/4
----------
train Loss: 21.8259 Acc: 0.4672
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:32:37,827] Trial 1 finished with value: 0.5686274509803921 and
parameters: \{'model\_name': 'vgg16', 'lr': 0.005366941939750931,
'optimizer\_name': 'Adam'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.7004 Acc: 0.5425

Training complete in 7m 4s
Best val Acc: 0.568627
Epoch 0/4
----------
train Loss: 0.6187 Acc: 0.6475
val Loss: 0.4011 Acc: 0.8693

Epoch 1/4
----------
train Loss: 0.5138 Acc: 0.7418
val Loss: 0.2897 Acc: 0.9346

Epoch 2/4
----------
train Loss: 0.4449 Acc: 0.7705
val Loss: 0.2511 Acc: 0.9216

Epoch 3/4
----------
train Loss: 0.4241 Acc: 0.7992
val Loss: 0.2305 Acc: 0.9150

Epoch 4/4
----------
train Loss: 0.3511 Acc: 0.8402
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:34:05,586] Trial 2 finished with value: 0.934640522875817 and
parameters: \{'model\_name': 'resnet18', 'lr': 0.0016671673715747957,
'optimizer\_name': 'SGD'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.2090 Acc: 0.9346

Training complete in 1m 28s
Best val Acc: 0.934641
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{best\PYZus{}trial} \PY{o}{=} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ğğğ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor prueba:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  NÃºmero de prueba: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Modelo seleccionado: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Learning rate (lr): }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Optimizador seleccionado: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  PrecisiÃ³n obtenida: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Fecha y hora de inicio: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{datetime\PYZus{}start}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Fecha y hora de finalizaciÃ³n: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{datetime\PYZus{}complete}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  MÃ©tricas intermedias:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{step}\PY{p}{,} \PY{n}{value} \PY{o+ow}{in} \PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{intermediate\PYZus{}values}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{    Paso }\PY{l+s+si}{\PYZob{}}\PY{n}{step}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
ğğğ
Mejor prueba:
  NÃºmero de prueba: 0
  Modelo seleccionado: resnet18
  Learning rate (lr): 0.0008709086527787754
  Optimizador seleccionado: SGD
  PrecisiÃ³n obtenida: 0.934640522875817
  Fecha y hora de inicio: 2024-06-20 09:24:20.993162
  Fecha y hora de finalizaciÃ³n: 2024-06-20 09:25:33.401369
  MÃ©tricas intermedias:
    Paso 0: 0.7843137254901961
    Paso 1: 0.869281045751634
    Paso 2: 0.9150326797385621
    Paso 3: 0.9019607843137255
    Paso 4: 0.934640522875817
    \end{Verbatim}

    \hypertarget{anuxe1lisis-de-sensibilidad-y-robustez}{%
\subsection{6. AnÃ¡lisis de sensibilidad y
robustez:}\label{anuxe1lisis-de-sensibilidad-y-robustez}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Realizar un anÃ¡lisis de sensibilidad para identificar quÃ©
  hiperparÃ¡metros son mÃ¡s influyentes en el rendimiento del modelo.
  \textbackslash{}
\item
  Investigar la robustez de los modelos optimizados en condiciones de
  variaciÃ³n de datos, como ruido o cambios en la distribuciÃ³n de los
  datos.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{plotly}
\PY{n}{plotly}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
'5.22.0'
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{pickle}

\PY{c+c1}{\PYZsh{} Guardar el estudio actual en un archivo}
\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{study.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
    \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{study}\PY{p}{,} \PY{n}{f}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{pickle}

\PY{c+c1}{\PYZsh{} Para cargar el estudio despuÃ©s de reiniciar el kernel}
\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{study.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
    \PY{n}{study} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{plot\PYZus{}parallel\PYZus{}coordinate}\PY{p}{(}\PY{n}{study}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{renderer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{browser}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Opening in existing browser session.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}parallel\PYZus{}coordinate}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1386379/437109074.py:1: ExperimentalWarning:

plot\_parallel\_coordinate is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Parallel Coordinate Plot'\}>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_65_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{plot\PYZus{}contour}\PY{p}{(}\PY{n}{study}\PY{p}{,} \PY{n}{params}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{renderer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{browser}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Opening in existing browser session.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{IPython} \PY{k+kn}{import} \PY{n}{display}
\PY{n}{display}\PY{o}{.}\PY{n}{Image}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{https://i.ibb.co/56X2BYB/download2.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{10}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_67_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}optuna.visualization.matplotlib.plot\PYZus{}contour(study, params=[\PYZsq{}optimizer\PYZus{}name\PYZsq{},\PYZsq{}model\PYZus{}name\PYZsq{}])}
\end{Verbatim}
\end{tcolorbox}

    GrÃ¡ficos de cortes para cada uno de los hiperparÃ¡metros:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}slice}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1386379/2375574420.py:1: ExperimentalWarning:

plot\_slice is experimental (supported from v2.2.0). The interface can change in
the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([<Axes: xlabel='lr', ylabel='Objective Value'>,
       <Axes: xlabel='model\_name'>, <Axes: xlabel='optimizer\_name'>],
      dtype=object)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_70_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Importancia de los hiperparÃ¡metros:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{sklearn}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}param\PYZus{}importances}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/1785110159.py:3: ExperimentalWarning:

plot\_param\_importances is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'left': 'Hyperparameter Importances'\}, xlabel='Hyperparameter
Importance', ylabel='Hyperparameter'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_72_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Trazar el historial de optimizaciÃ³n de todos los ensayos de un estudio:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}optimization\PYZus{}history}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/1455980257.py:1: ExperimentalWarning:

plot\_optimization\_history is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Optimization History Plot'\}, xlabel='Trial',
ylabel='Objective Value'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_74_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Curvas de aprendizaje de los ensayos:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}intermediate\PYZus{}values}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/2140463885.py:1: ExperimentalWarning:

plot\_intermediate\_values is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Intermediate Values Plot'\}, xlabel='Step',
ylabel='Intermediate Value'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{automatizaciuxf3n-y-escalabilidad-del-proceso-de-optimizaciuxf3n-opcional}{%
\subsection{7. AutomatizaciÃ³n y escalabilidad del proceso de
optimizaciÃ³n
(opcional):}\label{automatizaciuxf3n-y-escalabilidad-del-proceso-de-optimizaciuxf3n-opcional}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Desarrollar un framework automatizado que pueda escalar la
  optimizaciÃ³n de hiperparÃ¡metros a mÃºltiples mÃ¡quinas o GPUs.
  \textbackslash{}
\item
  Utilizar Optuna en un entorno de com putaciÃ³n distribuida para manejar
  grandes volÃºmenes de pruebas de hiperparÃ¡metros de manera eficiente.
\end{enumerate}

    \hypertarget{documentaciuxf3n-de-resultados}{%
\subsection{8. DocumentaciÃ³n de
resultados:}\label{documentaciuxf3n-de-resultados}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Preparar una documentaciÃ³n que describa los mÃ©todos utilizados, los
  resultados obtenidos y las recomendaciones para futuras
  investigaciones. \textbackslash{}
\item
  Publicar los hallazgos en un artÃ­culo de conferencia o revista,
  enfocÃ¡ndose en cÃ³mo la optimizaciÃ³n de hiperparÃ¡metros puede mejorar
  significativamente los modelos de aprendizaje profundo (opcional).
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
