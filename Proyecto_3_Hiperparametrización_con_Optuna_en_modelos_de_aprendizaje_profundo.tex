\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Keep aspect ratio if custom image width or height is specified
    \setkeys{Gin}{keepaspectratio}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Proyecto\_3\_Hiperparametrización\_con\_Optuna\_en\_modelos\_de\_aprendizaje\_profundo}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{proyecto-3-hiperparametrizaciuxf3n-con-optuna-en-modelos-de-aprendizaje-profundo}{%
\section{Proyecto 3 Hiperparametrización con Optuna en modelos de
aprendizaje
profundo}\label{proyecto-3-hiperparametrizaciuxf3n-con-optuna-en-modelos-de-aprendizaje-profundo}}

    \hypertarget{introducciuxf3n-a-optuna-y-configuraciuxf3n-inicial}{%
\subsection{1. Introducción a optuna y configuración
inicial:}\label{introducciuxf3n-a-optuna-y-configuraciuxf3n-inicial}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Estudiar los fundamentos y características de Optuna, incluyendo su
  arquitectura y métodos de optimización. \textbackslash{}
\item
  Preparar un entorno de desarrollo en PyTorch y configurar Optuna para
  integrarse con modelos de aprendizaje profundo.
\end{enumerate}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \hypertarget{introducciuxf3n}{%
\subsubsection{Introducción}\label{introducciuxf3n}}

    La búsqueda de hiperparámetros forma parte de casi todos los proyectos
de aprendizaje automático y aprendizaje profundo. Cuando seleccionamos
un modelo candidato, nos aseguramos de que generalize a los datos de
prueba de la mejor manera posible.

Seleccionar manualmente los mejores hiperparámetros es fácil si se trata
de un modelo sencillo como la regresión lineal. Para modelos complejos
como las redes neuronales, el ajuste manual es difícil.

Por ejemplo, si entrenamos una red neuronal con sólo capas lineales,
aquí tenemos un conjunto potencial de hiperparámetros:

    \begin{itemize}
\tightlist
\item
  Número de capas
\item
  Unidades por capa
\item
  Función de activación
\item
  Tasa de aprendizaje
\item
  etc.
\end{itemize}

    A menudo, para optimizar los hiperparámetros se utilizan métodos Grid
Search y Random Search.

    Por ejemplo, digamos que tenemos 3 valores candidatos para cada una de
esas 4 variables, acabamos con 3\^{}4 = 81 experimentos. Para redes más
grandes y más valores candidatos, este número se vuelve abrumador.

    Estos dos enfoques consumen mucho tiempo y recursos. Los algoritmos de
aprendizaje profundo actuales a menudo contienen muchos hiperparámetros,
y se tarda días, semanas en entrenar un buen modelo. Simplemente no es
posible forzar сombinaciones de hiperparámetros y entrenar modelos
separados para cada uno sin ninguna optimización.

    \hypertarget{optuna}{%
\subsubsection{Optuna}\label{optuna}}

    Para esto se creo \textbf{Optuna}, que es una biblioteca de Python
utilizada para la optimización de hiperparámetros.

    \textbf{Optuna combina mecanismos de muestreo (sampling) y poda
(pruning) para proporcionar una optimización eficiente de los
hiperparámetros.}

    Optuna utiliza el muestreo para explorar el espacio de búsqueda de
hiperparámetros. Sugiere nuevos valores de hiperparámetros basándose en
ensayos anteriores y en el algoritmo de optimización utilizado. Ofrece
distintas estrategias de muestreo:

\begin{itemize}
\tightlist
\item
  Grid Search implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.GridSampler.html\#optuna.samplers.GridSampler}{GridSampler}
\item
  Random Search implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.RandomSampler.html\#optuna.samplers.RandomSampler}{RandomSampler}
\item
  Tree-structured Parzen Estimator algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html\#optuna.samplers.TPESampler}{TPESampler}
\item
  CMA-ES based algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html\#optuna.samplers.CmaEsSampler}{CmaEsSampler}
\item
  Algoritmo para activar parámetros fijos parciales implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.PartialFixedSampler.html\#optuna.samplers.PartialFixedSampler}{PartialFixedSampler}
\item
  Non-dominated Sorting Genetic Algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.NSGAIISampler.html\#optuna.samplers.NSGAIISampler}{NSGAIISampler}
\item
  uasi Monte Carlo sampling algorithm implementado en
  \href{https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.QMCSampler.html\#optuna.samplers.QMCSampler}{QMCSampler}
\end{itemize}

    Tambien proporciona mecanismos para detener y podar tempranamente
ensayos poco prometedores. Supervisa continuamente el progreso de las
pruebas y elimina aquellas que probablemente no produzcan mejores
resultados, ahorrando tiempo y recursos computacionales. Las decisiones
de poda se toman con base en los resultados intermedios informados por
la función objetivo durante la evaluación de un ensayo.

    \hypertarget{caracteruxedsticas-principales-de-optuna}{%
\subsubsection{Características principales de
Optuna:}\label{caracteruxedsticas-principales-de-optuna}}

    Según los \href{https://optuna.org/}{autores de Optuna}, son tres las
características que la hacen destacar: - Eager search spaces: Automated
search for optimal hyperparameters using Python conditionals, loops, and
syntax - State-of-the-art algorithms: Efficiently search large spaces
and prune unpromising trials for faster results - Easy parallelization:
Parallelize hyperparameter searches over multiple threads or processes
without modifying code

    \hypertarget{flujo-de-trabajo}{%
\subsubsection{Flujo de trabajo}\label{flujo-de-trabajo}}

    El flujo de trabajo de Optuna se resuelve en torno a dos términos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ensayo (Trial): Una única llamada a una función objetivo.
\item
  Estudio (Study): Optimización de hiperparámetros basada en una función
  objetivo. Un estudio tiene como objetivo determinar el conjunto ideal
  de valores de hiperparámetros mediante la realización de varios
  ensayos.
\end{enumerate}

    \hypertarget{integraciuxf3n-de-optuna-y-pytorch}{%
\subsubsection{Integración de Optuna y
PyTorch}\label{integraciuxf3n-de-optuna-y-pytorch}}

    Ahora, vamos a desglosar el proceso de optimización de hiperparámetros
con Optuna.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{torchvision}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting torchvision
  Downloading torchvision-0.18.1-cp312-cp312-manylinux1\_x86\_64.whl.metadata (6.6
kB)
Requirement already satisfied: numpy in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torchvision) (2.0.0)
Requirement already satisfied: torch==2.3.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torchvision) (2.3.1)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)
  Downloading pillow-10.3.0-cp312-cp312-manylinux\_2\_28\_x86\_64.whl.metadata (9.2
kB)
Requirement already satisfied: filelock in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (3.15.3)
Requirement already satisfied: typing-extensions>=4.8.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (4.12.2)
Requirement already satisfied: sympy in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision) (1.12.1)
Requirement already satisfied: networkx in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (3.3)
Requirement already satisfied: jinja2 in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision) (3.1.4)
Requirement already satisfied: fsspec in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch==2.3.1->torchvision)
(2024.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch==2.3.1->torchvision) (12.1.105)
Requirement already satisfied: nvidia-nvjitlink-cu12 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision) (12.5.40)
Requirement already satisfied: MarkupSafe>=2.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from jinja2->torch==2.3.1->torchvision) (2.1.5)
Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from sympy->torch==2.3.1->torchvision) (1.3.0)
Downloading torchvision-0.18.1-cp312-cp312-manylinux1\_x86\_64.whl (7.0 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{7.0/7.0 MB} \textcolor{ansi-red}{1.4 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading pillow-10.3.0-cp312-cp312-manylinux\_2\_28\_x86\_64.whl (4.5 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{4.5/4.5 MB} \textcolor{ansi-red}{1.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:010m
Installing collected packages: pillow, torchvision
Successfully installed pillow-10.3.0 torchvision-0.18.1
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{optuna}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting optuna
  Using cached optuna-3.6.1-py3-none-any.whl.metadata (17 kB)
Collecting alembic>=1.5.0 (from optuna)
  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)
Collecting colorlog (from optuna)
  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)
Collecting numpy (from optuna)
  Using cached
numpy-2.0.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata
(60 kB)
Requirement already satisfied: packaging>=20.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from optuna) (24.1)
Collecting sqlalchemy>=1.3.0 (from optuna)
  Using cached SQLAlchemy-2.0.31-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (9.6 kB)
Collecting tqdm (from optuna)
  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)
     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{57.6/57.6 kB} \textcolor{ansi-red}{728.0 kB/s} eta \textcolor{ansi-cyan}{0:00:00}MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Requirement already satisfied: PyYAML in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from optuna) (6.0.1)
Collecting Mako (from alembic>=1.5.0->optuna)
  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)
  Using cached typing\_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)
  Using cached greenlet-3.0.3-cp312-cp312-
manylinux\_2\_24\_x86\_64.manylinux\_2\_28\_x86\_64.whl.metadata (3.8 kB)
Requirement already satisfied: MarkupSafe>=0.9.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from Mako->alembic>=1.5.0->optuna) (2.1.5)
Using cached optuna-3.6.1-py3-none-any.whl (380 kB)
Using cached alembic-1.13.1-py3-none-any.whl (233 kB)
Using cached
SQLAlchemy-2.0.31-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl
(3.2 MB)
Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)
Using cached
numpy-2.0.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (19.0 MB)
Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{78.3/78.3 kB} \textcolor{ansi-red}{2.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}
Using cached
greenlet-3.0.3-cp312-cp312-manylinux\_2\_24\_x86\_64.manylinux\_2\_28\_x86\_64.whl (625
kB)
Using cached typing\_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached Mako-1.3.5-py3-none-any.whl (78 kB)
Installing collected packages: typing-extensions, tqdm, numpy, Mako, greenlet,
colorlog, sqlalchemy, alembic, optuna
Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 greenlet-3.0.3
numpy-2.0.0 optuna-3.6.1 sqlalchemy-2.0.31 tqdm-4.66.4 typing-extensions-4.12.2
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{torch}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting torch
  Downloading torch-2.3.1-cp312-cp312-manylinux1\_x86\_64.whl.metadata (26 kB)
Collecting filelock (from torch)
  Downloading filelock-3.15.3-py3-none-any.whl.metadata (2.9 kB)
Requirement already satisfied: typing-extensions>=4.8.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from torch) (4.12.2)
Collecting sympy (from torch)
  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch)
  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)
Requirement already satisfied: jinja2 in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from torch) (3.1.4)
Collecting fsspec (from torch)
  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_nvrtc\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_runtime\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)
  Downloading nvidia\_cuda\_cupti\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)
  Downloading nvidia\_cudnn\_cu12-8.9.2.26-py3-none-manylinux1\_x86\_64.whl.metadata
(1.6 kB)
Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)
  Downloading nvidia\_cublas\_cu12-12.1.3.1-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)
  Downloading nvidia\_cufft\_cu12-11.0.2.54-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.2.106 (from torch)
  Downloading nvidia\_curand\_cu12-10.3.2.106-py3-none-
manylinux1\_x86\_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)
  Downloading nvidia\_cusolver\_cu12-11.4.5.107-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)
  Downloading nvidia\_cusparse\_cu12-12.1.0.106-py3-none-
manylinux1\_x86\_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12==2.20.5 (from torch)
  Downloading nvidia\_nccl\_cu12-2.20.5-py3-none-manylinux2014\_x86\_64.whl.metadata
(1.8 kB)
Collecting nvidia-nvtx-cu12==12.1.105 (from torch)
  Downloading nvidia\_nvtx\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl.metadata
(1.7 kB)
Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)
  Downloading nvidia\_nvjitlink\_cu12-12.5.40-py3-none-
manylinux2014\_x86\_64.whl.metadata (1.5 kB)
Requirement already satisfied: MarkupSafe>=2.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from jinja2->torch) (2.1.5)
Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)
  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Downloading torch-2.3.1-cp312-cp312-manylinux1\_x86\_64.whl (779.1 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{779.1/779.1 MB} \textcolor{ansi-red}{3.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:04m
Downloading nvidia\_cublas\_cu12-12.1.3.1-py3-none-manylinux1\_x86\_64.whl
(410.6 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{410.6/410.6 MB} \textcolor{ansi-red}{4.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:02
Downloading nvidia\_cuda\_cupti\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl
(14.1 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{14.1/14.1 MB} \textcolor{ansi-red}{6.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading nvidia\_cuda\_nvrtc\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl
(23.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{23.7/23.7 MB} \textcolor{ansi-red}{6.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading nvidia\_cuda\_runtime\_cu12-12.1.105-py3-none-
manylinux1\_x86\_64.whl (823 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{823.6/823.6 kB} \textcolor{ansi-red}{7.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01
Downloading nvidia\_cudnn\_cu12-8.9.2.26-py3-none-manylinux1\_x86\_64.whl
(731.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{731.7/731.7 MB} \textcolor{ansi-red}{3.5 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:03
Downloading nvidia\_cufft\_cu12-11.0.2.54-py3-none-manylinux1\_x86\_64.whl
(121.6 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{121.6/121.6 MB} \textcolor{ansi-red}{5.7 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_curand\_cu12-10.3.2.106-py3-none-manylinux1\_x86\_64.whl
(56.5 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{56.5/56.5 MB} \textcolor{ansi-red}{6.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_cusolver\_cu12-11.4.5.107-py3-none-manylinux1\_x86\_64.whl
(124.2 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{124.2/124.2 MB} \textcolor{ansi-red}{5.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_cusparse\_cu12-12.1.0.106-py3-none-manylinux1\_x86\_64.whl
(196.0 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{196.0/196.0 MB} \textcolor{ansi-red}{4.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nccl\_cu12-2.20.5-py3-none-manylinux2014\_x86\_64.whl
(176.2 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{176.2/176.2 MB} \textcolor{ansi-red}{5.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nvtx\_cu12-12.1.105-py3-none-manylinux1\_x86\_64.whl (99
kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{99.1/99.1 kB} \textcolor{ansi-red}{1.7 MB/s} eta \textcolor{ansi-cyan}{0:00:00} MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Downloading filelock-3.15.3-py3-none-any.whl (16 kB)
Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{176.9/176.9 kB} \textcolor{ansi-red}{3.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}\textcolor{ansi-cyan}{0:00:01}
Downloading networkx-3.3-py3-none-any.whl (1.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{1.7/1.7 MB} \textcolor{ansi-red}{8.0 MB/s} eta \textcolor{ansi-cyan}{0:00:00}[31m8.2 MB/s eta
\textcolor{ansi-cyan}{0:00:01}
Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{5.7/5.7 MB} \textcolor{ansi-red}{6.4 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{536.2/536.2 kB} \textcolor{ansi-red}{7.2 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading nvidia\_nvjitlink\_cu12-12.5.40-py3-none-
manylinux2014\_x86\_64.whl (21.3 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{21.3/21.3 MB} \textcolor{ansi-red}{6.8 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-
nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-
cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-
cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-
cu12, nvidia-cusolver-cu12, torch
Successfully installed filelock-3.15.3 fsspec-2024.6.0 mpmath-1.3.0 networkx-3.3
nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-
cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26
nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-
cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-
nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sympy-1.12.1 torch-2.3.1
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{matplotlib}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Collecting matplotlib
  Downloading matplotlib-3.9.0-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (11 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Downloading contourpy-1.2.1-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (5.8 kB)
Collecting cycler>=0.10 (from matplotlib)
  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Downloading fonttools-4.53.0-cp312-cp312-
manylinux\_2\_5\_x86\_64.manylinux1\_x86\_64.manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_6
4.whl.metadata (162 kB)
     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{162.2/162.2 kB} \textcolor{ansi-red}{906.0 kB/s} eta \textcolor{ansi-cyan}{0:00:00} kB/s eta
\textcolor{ansi-cyan}{0:00:01}:01
Collecting kiwisolver>=1.3.1 (from matplotlib)
  Downloading kiwisolver-1.4.5-cp312-cp312-
manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl.metadata (6.4 kB)
Requirement already satisfied: numpy>=1.23 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (2.0.0)
Requirement already satisfied: packaging>=20.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (24.1)
Requirement already satisfied: pillow>=8 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (10.3.0)
Collecting pyparsing>=2.3.1 (from matplotlib)
  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)
Requirement already satisfied: python-dateutil>=2.7 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from matplotlib) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from python-dateutil>=2.7->matplotlib) (1.16.0)
Downloading
matplotlib-3.9.0-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (8.3
MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{8.3/8.3 MB} \textcolor{ansi-red}{2.9 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}0:01:01
Downloading
contourpy-1.2.1-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (309
kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{309.2/309.2 kB} \textcolor{ansi-red}{13.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00} eta
\textcolor{ansi-cyan}{-:--:--}
Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Downloading fonttools-4.53.0-cp312-cp312-
manylinux\_2\_5\_x86\_64.manylinux1\_x86\_64.manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_6
4.whl (4.9 MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{4.9/4.9 MB} \textcolor{ansi-red}{5.6 MB/s} eta \textcolor{ansi-cyan}{0:00:00}m eta
\textcolor{ansi-cyan}{0:00:01}[36m0:00:01
Downloading
kiwisolver-1.4.5-cp312-cp312-manylinux\_2\_17\_x86\_64.manylinux2014\_x86\_64.whl (1.5
MB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{1.5/1.5 MB} \textcolor{ansi-red}{8.2 MB/s} eta \textcolor{ansi-cyan}{0:00:00}[31m9.2 MB/s eta
\textcolor{ansi-cyan}{0:00:01}m
Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)
   \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{114,156,31}}{━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━}
\textcolor{ansi-green}{103.2/103.2 kB} \textcolor{ansi-red}{11.1 MB/s} eta \textcolor{ansi-cyan}{0:00:00}
Installing collected packages: pyparsing, kiwisolver, fonttools, cycler,
contourpy, matplotlib
Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0
kiwisolver-1.4.5 matplotlib-3.9.0 pyparsing-3.1.2
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{time}
\PY{k+kn}{import} \PY{n+nn}{copy}

\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}

\PY{k+kn}{import} \PY{n+nn}{torchvision}
\PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k+kn}{import} \PY{n}{datasets}\PY{p}{,} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}

\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{optimizaciuxf3n-de-un-modelo-de-clasificaciuxf3n-de-imuxe1genes}{%
\subsection{2. Optimización de un modelo de clasificación de
imágenes:}\label{optimizaciuxf3n-de-un-modelo-de-clasificaciuxf3n-de-imuxe1genes}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Implementar un modelo convencional como ResNet o VGG en PyTorch.
  \textbackslash{}
\item
  Utilizar Optuna para optimizar hiperparámetros como tasa de
  aprendizaje, tamaño de lote, y configuraciones específicas de capas.
  \textbackslash{}
\item
  Evaluar las mejoras en precisión y tiempo de entrenamiento tras la
  optimización de hiperparámetros
\end{enumerate}

    El modelo SimpleVGG define capas convolucionales seguidas de capas de
pooling y capas completamente conectadas para la clasificación. La
función objetivo (objective) carga un subconjunto del conjunto de datos
CIFAR10, define hiperparámetros a optimizar con Optuna, entrena el
modelo y evalúa su precisión en un conjunto de prueba más pequeño.
Optuna se utiliza para encontrar los mejores hiperparámetros en un
número limitado de pruebas (n\_trials).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{transforms} \PY{k}{as} \PY{n+nn}{transforms}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{as} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}

\PY{c+c1}{\PYZsh{} Modelo VGG}
\PY{k}{class} \PY{n+nc}{SimpleVGG}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{SimpleVGG}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128} \PY{o}{*} \PY{l+m+mi}{4} \PY{o}{*} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{)}
        \PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Definimos la función objetivo para optimizar con Optuna}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Cargamos un subconjunto del dataset CIFAR10}
    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}train} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)} \PY{c+c1}{\PYZsh{} download=True}
    \PY{n}{cifar10\PYZus{}test} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Usamos un subconjunto más pequeño del dataset}
    \PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{2000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{2000}\PY{p}{]}\PY{p}{)}
    \PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{500}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{500}\PY{p}{]}\PY{p}{)}

    \PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{testloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos los hiperparámetros a optimizar}
    \PY{n}{lr} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{weight\PYZus{}decay} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{momentum} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{momentum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos el modelo, el optimizador y la función de pérdida}
    \PY{n}{model} \PY{o}{=} \PY{n}{SimpleVGG}\PY{p}{(}\PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
    \PY{n}{optimizer} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{SGD}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{,} \PY{n}{momentum}\PY{o}{=}\PY{n}{momentum}\PY{p}{,} \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{weight\PYZus{}decay}\PY{p}{)}
    \PY{n}{loss\PYZus{}fn} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Entrenamos el modelo por una época}
    \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{trainloader}\PY{p}{:}
        \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}
        \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        \PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fn}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{target}\PY{p}{)}
        \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
        \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Evaluamos el modelo en el conjunto de prueba}
    \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
    \PY{n}{correct} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{testloader}\PY{p}{:}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{pred} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keepdim}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            \PY{n}{correct} \PY{o}{+}\PY{o}{=} \PY{n}{pred}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{target}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{pred}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Calculamos la precisión en el conjunto de prueba y devolverla como el valor objetivo para Optuna}
    \PY{n}{accuracy} \PY{o}{=} \PY{n}{correct} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{testloader}\PY{o}{.}\PY{n}{dataset}\PY{p}{)}
    \PY{k}{return} \PY{n}{accuracy}

\PY{c+c1}{\PYZsh{} Ejecutamos el estudio de Optuna para optimizar los hiperparámetros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{maximize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Número reducido de pruebas por simplicidad}

\PY{c+c1}{\PYZsh{} Imprimimos los mejores hiperparámetros y el mejor valor objetivo encontrado por Optuna}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{🎉🎉🎉}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores hiperparámetros: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor objetivo: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 07:01:28,335] A new study created in memory with name: no-
name-c5cb197f-cc90-4c1b-965c-48768eb6ad3e
[I 2024-06-20 07:01:29,995] Trial 0 finished with value: 0.124 and parameters:
\{'lr': 0.0013185037936517044, 'weight\_decay': 1.0101876084844885e-05,
'momentum': 0.31937225365824595\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:31,628] Trial 1 finished with value: 0.112 and parameters:
\{'lr': 0.0069775700774503385, 'weight\_decay': 1.7158918060121343e-05,
'momentum': 0.777572700493663\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:33,215] Trial 2 finished with value: 0.114 and parameters:
\{'lr': 0.000603989798307354, 'weight\_decay': 0.0003455069810528488, 'momentum':
0.9677030275876205\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:34,810] Trial 3 finished with value: 0.094 and parameters:
\{'lr': 0.00013414570624012488, 'weight\_decay': 0.017267488501468326, 'momentum':
0.9522947167311789\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:36,404] Trial 4 finished with value: 0.096 and parameters:
\{'lr': 0.0010732445095242844, 'weight\_decay': 0.011335276993393881, 'momentum':
0.7190933888877701\}. Best is trial 0 with value: 0.124.
[I 2024-06-20 07:01:38,015] Trial 5 finished with value: 0.14 and parameters:
\{'lr': 0.014285162980527384, 'weight\_decay': 0.00016529654230712488, 'momentum':
0.4701801898545127\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:39,629] Trial 6 finished with value: 0.114 and parameters:
\{'lr': 0.01996216276609492, 'weight\_decay': 0.0007625124257630504, 'momentum':
0.6777808179202709\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:41,211] Trial 7 finished with value: 0.114 and parameters:
\{'lr': 0.00048446766440926364, 'weight\_decay': 0.0002085832437380734,
'momentum': 0.3666190394436756\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:42,846] Trial 8 finished with value: 0.114 and parameters:
\{'lr': 0.0005399413956820914, 'weight\_decay': 0.00018445293075448918,
'momentum': 0.6165325947948295\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:44,529] Trial 9 finished with value: 0.118 and parameters:
\{'lr': 0.00598216984259799, 'weight\_decay': 0.04913580697800302, 'momentum':
0.8526936603961539\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:46,156] Trial 10 finished with value: 0.096 and parameters:
\{'lr': 0.07706220685173414, 'weight\_decay': 0.003245565578180795, 'momentum':
0.048390421090106384\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:47,797] Trial 11 finished with value: 0.082 and parameters:
\{'lr': 0.026709407462641235, 'weight\_decay': 1.2567345579514115e-05, 'momentum':
0.3578085575017036\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:49,423] Trial 12 finished with value: 0.092 and parameters:
\{'lr': 0.00220325706718249, 'weight\_decay': 5.506630406102414e-05, 'momentum':
0.2390763704654537\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:51,125] Trial 13 finished with value: 0.092 and parameters:
\{'lr': 0.01008819509715368, 'weight\_decay': 6.156035815462389e-05, 'momentum':
0.5108930572112749\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:52,795] Trial 14 finished with value: 0.084 and parameters:
\{'lr': 0.002498175105308497, 'weight\_decay': 5.0457871802685105e-05, 'momentum':
0.1687453843903708\}. Best is trial 5 with value: 0.14.
[I 2024-06-20 07:01:54,429] Trial 15 finished with value: 0.144 and parameters:
\{'lr': 0.08899241419385215, 'weight\_decay': 0.0024542995513446913, 'momentum':
0.4625382849823203\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:56,033] Trial 16 finished with value: 0.102 and parameters:
\{'lr': 0.08302048956120808, 'weight\_decay': 0.002112499752842944, 'momentum':
0.5198272525214307\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:57,648] Trial 17 finished with value: 0.138 and parameters:
\{'lr': 0.032588654888491546, 'weight\_decay': 0.0038768731862778654, 'momentum':
0.4550066027690283\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:01:59,361] Trial 18 finished with value: 0.124 and parameters:
\{'lr': 0.04967893602111068, 'weight\_decay': 0.00087695279443526, 'momentum':
0.6205566987029656\}. Best is trial 15 with value: 0.144.
[I 2024-06-20 07:02:01,135] Trial 19 finished with value: 0.144 and parameters:
\{'lr': 0.014931709180985353, 'weight\_decay': 0.0004543863409564157, 'momentum':
0.4339534081173413\}. Best is trial 15 with value: 0.144.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
🎉🎉🎉
Mejores hiperparámetros: \{'lr': 0.08899241419385215, 'weight\_decay':
0.0024542995513446913, 'momentum': 0.4625382849823203\}
Mejor valor objetivo: 0.144
    \end{Verbatim}

    Los resultados que estamos obteniendo son un poco bajos para el conjunto
de datos CIFAR-10, aunque se debe considerar que hemos reducido
significativamente la complejidad del modelo y el tamaño del subconjunto
de datos.

Ahora modificaremos el codigo un poco, el cual incrementa el número de
épocas y usa un subconjunto de datos más grande:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{transforms} \PY{k}{as} \PY{n+nn}{transforms}
\PY{k+kn}{import} \PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{as} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}

\PY{c+c1}{\PYZsh{} Definimos un modelo VGG simplificado}
\PY{k}{class} \PY{n+nc}{SimpleVGG}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{SimpleVGG}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}

            \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128} \PY{o}{*} \PY{l+m+mi}{4} \PY{o}{*} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
            \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{)}
        \PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{features}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Definimos la función objetivo para optimizar con Optuna}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Cargamos un subconjunto del dataset CIFAR10}
    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}train} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}
    \PY{n}{cifar10\PYZus{}test} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{CIFAR10}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Usamos un subconjunto más pequeño del dataset}
    \PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{5000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}train}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{5000}\PY{p}{]}\PY{p}{)}
    \PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{random\PYZus{}split}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cifar10\PYZus{}test}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}

    \PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}train}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{testloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{small\PYZus{}test}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos los hiperparámetros a optimizar}
    \PY{n}{lr} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{weight\PYZus{}decay} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{momentum} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{momentum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Definimos el modelo, el optimizador y la función de pérdida}
    \PY{n}{model} \PY{o}{=} \PY{n}{SimpleVGG}\PY{p}{(}\PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
    \PY{n}{optimizer} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{SGD}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{,} \PY{n}{momentum}\PY{o}{=}\PY{n}{momentum}\PY{p}{,} \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{weight\PYZus{}decay}\PY{p}{)}
    \PY{n}{loss\PYZus{}fn} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Entrenamos el modelo por 5 épocas}
    \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}  \PY{c+c1}{\PYZsh{} Incrementa el número de épocas}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{trainloader}\PY{p}{:}
            \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fn}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{target}\PY{p}{)}
            \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
            \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Evaluamos el modelo en el conjunto de prueba}
    \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
    \PY{n}{correct} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{data}\PY{p}{,} \PY{n}{target} \PY{o+ow}{in} \PY{n}{testloader}\PY{p}{:}
            \PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{pred} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keepdim}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            \PY{n}{correct} \PY{o}{+}\PY{o}{=} \PY{n}{pred}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{target}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{pred}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Calculamos la precisión en el conjunto de prueba y devolverla como el valor objetivo para Optuna}
    \PY{n}{accuracy} \PY{o}{=} \PY{n}{correct} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{testloader}\PY{o}{.}\PY{n}{dataset}\PY{p}{)}
    \PY{k}{return} \PY{n}{accuracy}

\PY{c+c1}{\PYZsh{} Ejecutamos el estudio de Optuna para optimizar los hiperparámetros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{maximize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Número reducido de pruebas por simplicidad}

\PY{c+c1}{\PYZsh{} Imprimimos los mejores hiperparámetros y el mejor valor objetivo encontrado por Optuna}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores hiperparámetros: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor objetivo: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 07:02:40,477] A new study created in memory with name: no-
name-f314dfe2-7380-41db-b47b-6540247e8175
[I 2024-06-20 07:02:53,819] Trial 0 finished with value: 0.198 and parameters:
\{'lr': 0.00845991323388558, 'weight\_decay': 4.05249623080612e-05, 'momentum':
0.21636263055137983\}. Best is trial 0 with value: 0.198.
[I 2024-06-20 07:03:06,944] Trial 1 finished with value: 0.185 and parameters:
\{'lr': 0.04328877533411029, 'weight\_decay': 0.0032581492626639567, 'momentum':
0.1560813751939938\}. Best is trial 0 with value: 0.198.
[I 2024-06-20 07:03:20,391] Trial 2 finished with value: 0.263 and parameters:
\{'lr': 0.018164393518388437, 'weight\_decay': 0.012957315385372072, 'momentum':
0.8973338245769505\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:33,203] Trial 3 finished with value: 0.234 and parameters:
\{'lr': 0.001902261227532657, 'weight\_decay': 0.022056829136624552, 'momentum':
0.9881619924809797\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:46,146] Trial 4 finished with value: 0.137 and parameters:
\{'lr': 0.06700217000901784, 'weight\_decay': 0.00090189347600982, 'momentum':
0.19922116435475745\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:03:58,859] Trial 5 finished with value: 0.206 and parameters:
\{'lr': 0.04789214649477456, 'weight\_decay': 0.027853106740298263, 'momentum':
0.41128392428611493\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:04:11,669] Trial 6 finished with value: 0.13 and parameters:
\{'lr': 0.0009580519917326726, 'weight\_decay': 0.008775747071715556, 'momentum':
0.8396640451886481\}. Best is trial 2 with value: 0.263.
[I 2024-06-20 07:04:24,490] Trial 7 finished with value: 0.324 and parameters:
\{'lr': 0.06720776167555383, 'weight\_decay': 4.374825826675419e-05, 'momentum':
0.47966590440850343\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:04:36,882] Trial 8 finished with value: 0.107 and parameters:
\{'lr': 0.00288843840907154, 'weight\_decay': 0.0009721946398552832, 'momentum':
0.630922915233342\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:04:49,500] Trial 9 finished with value: 0.182 and parameters:
\{'lr': 0.021963597743462432, 'weight\_decay': 3.395403242544441e-05, 'momentum':
0.3876345278931973\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:03,185] Trial 10 finished with value: 0.124 and parameters:
\{'lr': 0.00010111637111118573, 'weight\_decay': 0.00018394766078888146,
'momentum': 0.6681767071833634\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:16,363] Trial 11 finished with value: 0.103 and parameters:
\{'lr': 0.010776510243293905, 'weight\_decay': 0.08247868750605579, 'momentum':
0.6599817795221479\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:29,278] Trial 12 finished with value: 0.098 and parameters:
\{'lr': 0.01223479007366479, 'weight\_decay': 1.1251620275673595e-05, 'momentum':
0.006142325466191978\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:41,783] Trial 13 finished with value: 0.09 and parameters:
\{'lr': 0.07694733849216753, 'weight\_decay': 0.0003343764676150295, 'momentum':
0.9945025204177538\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:05:54,433] Trial 14 finished with value: 0.248 and parameters:
\{'lr': 0.02300989668399209, 'weight\_decay': 0.005728819055967981, 'momentum':
0.5187607769567051\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:06,896] Trial 15 finished with value: 0.147 and parameters:
\{'lr': 0.0004412467845433172, 'weight\_decay': 0.00013059446951642492,
'momentum': 0.8100683966639503\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:20,110] Trial 16 finished with value: 0.145 and parameters:
\{'lr': 0.005218416684973856, 'weight\_decay': 0.00206167401248512, 'momentum':
0.5089084607879426\}. Best is trial 7 with value: 0.324.
[I 2024-06-20 07:06:32,850] Trial 17 finished with value: 0.398 and parameters:
\{'lr': 0.0237744576848544, 'weight\_decay': 1.3666934273072666e-05, 'momentum':
0.8165255624909171\}. Best is trial 17 with value: 0.398.
[I 2024-06-20 07:06:45,394] Trial 18 finished with value: 0.296 and parameters:
\{'lr': 0.08741406573595607, 'weight\_decay': 1.0086066506405488e-05, 'momentum':
0.752628067119733\}. Best is trial 17 with value: 0.398.
[I 2024-06-20 07:06:58,189] Trial 19 finished with value: 0.252 and parameters:
\{'lr': 0.031138160476250044, 'weight\_decay': 4.335467227065734e-05, 'momentum':
0.3358055693744339\}. Best is trial 17 with value: 0.398.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Mejores hiperparámetros: \{'lr': 0.0237744576848544, 'weight\_decay':
1.3666934273072666e-05, 'momentum': 0.8165255624909171\}
Mejor valor objetivo: 0.398
    \end{Verbatim}

    \hypertarget{experimentaciuxf3n-con-modelos-secuenciales-para-nlp}{%
\subsection{3. Experimentación con modelos secuenciales para
NLP:}\label{experimentaciuxf3n-con-modelos-secuenciales-para-nlp}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Aplicar Optuna en modelos LSTM o Transformer para tareas como
  traducción automática o generación de texto. \textbackslash{}
\item
  Optimizar hiperparámetros como el número de capas, la dimensión de los
  embeddings y los parámetros específicos de atención. \textbackslash{}
\item
  Analizar cómo la optimización afecta la calidad del texto generado y
  la velocidad de convergencia.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{datasets}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Requirement already satisfied: datasets in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(2.20.0)
Requirement already satisfied: filelock in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (3.15.3)
Requirement already satisfied: numpy>=1.17 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (2.0.0)
Requirement already satisfied: pyarrow>=15.0.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.3.8)
Requirement already satisfied: pandas in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (2.2.2)
Requirement already satisfied: requests>=2.32.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (2.32.3)
Requirement already satisfied: tqdm>=4.66.3 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (4.66.4)
Requirement already satisfied: xxhash in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (3.4.1)
Requirement already satisfied: multiprocess in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)
Requirement already satisfied: aiohttp in /home/abraham/miniconda3/envs/jupyter-
ipykernel/lib/python3.12/site-packages (from datasets) (3.9.5)
Requirement already satisfied: huggingface-hub>=0.21.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (0.23.4)
Requirement already satisfied: packaging in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (24.1)
Requirement already satisfied: pyyaml>=5.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from datasets) (6.0.1)
Requirement already satisfied: aiosignal>=1.1.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from aiohttp->datasets) (1.9.4)
Requirement already satisfied: typing-extensions>=3.7.4.3 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from huggingface-hub>=0.21.2->datasets) (4.12.2)
Requirement already satisfied: charset-normalizer<4,>=2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from requests>=2.32.2->datasets) (2024.6.2)
Requirement already satisfied: python-dateutil>=2.8.2 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from pandas->datasets) (2024.1)
Requirement already satisfied: six>=1.5 in
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages
(from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)
Note: you may need to restart the kernel to use updated packages.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}pip install \PYZhy{}U accelerate }
\PY{c+c1}{\PYZsh{}pip install \PYZhy{}U transformers}
\PY{c+c1}{\PYZsh{}los instale desde la consola}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{load\PYZus{}dataset}
\PY{k+kn}{from} \PY{n+nn}{transformers} \PY{k+kn}{import} \PY{p}{(}
    \PY{n}{AutoTokenizer}\PY{p}{,}
    \PY{n}{AutoModelForSequenceClassification}\PY{p}{,}
    \PY{n}{TrainingArguments}\PY{p}{,}
    \PY{n}{Trainer}\PY{p}{,}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} Cargar dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZus{}corpus\PYZus{}v2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ade\PYZus{}corpus\PYZus{}v2\PYZus{}classification}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Definir el nombre del modelo y tokenizer}
\PY{n}{model\PYZus{}name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bert\PYZhy{}base\PYZhy{}uncased}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{tokenizer} \PY{o}{=} \PY{n}{AutoTokenizer}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Función de preprocesamiento}
\PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{examples}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{tokenizer}\PY{p}{(}
        \PY{n}{examples}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{text}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{truncation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}length}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{64}
    \PY{p}{)}

\PY{c+c1}{\PYZsh{} Preprocesar el dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Función objetivo para optimización de hiperparámetros}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{:} \PY{n}{optuna}\PY{o}{.}\PY{n}{Trial}\PY{p}{)}\PY{p}{:}
    \PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}
    \PY{n}{output\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZhy{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{trial\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Directorio de salida único para cada ensayo}
    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{output\PYZus{}dir}\PY{p}{,} \PY{n}{exist\PYZus{}ok}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

    \PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
        \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{,}
        \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{,}
        \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
        \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
        \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
        \PY{n}{evaluation\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Evaluar al final de cada época}
        \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}         \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
        \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 100 pasos}
        \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
        \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
        \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
        \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
        \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{result} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{result}\PY{o}{.}\PY{n}{training\PYZus{}loss}

\PY{c+c1}{\PYZsh{} Optimizar hiperparámetros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{study\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hyper\PYZhy{}parameter\PYZhy{}search}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{minimize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Reducir el número de trials}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor de pérdida:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores parámetros:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor trial:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
Downloading readme: 100\%|███████████████████████████████████████████████████████
████████████████████| 10.2k/10.2k [00:00<00:00, 10.8MB/s]
Downloading data: 100\%|█████████████████████████████████████████████████████████
████████████████████| 1.71M/1.71M [00:01<00:00, 1.06MB/s]
Generating train split:
100\%|███████████████████████████████████████████████████████████| 23516/23516
[00:00<00:00, 801303.53 examples/s]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/huggingface\_hub/file\_download.py:1132: FutureWarning: `resume\_download`
is deprecated and will be removed in version 1.0.0. Downloads always resume when
possible. If you want to force a new download, use `force\_download=True`.
  warnings.warn(
Map: 100\%|██████████████████████████████████████████████████████████████████████
█████████| 18812/18812 [00:01<00:00, 15358.57 examples/s]
Map: 100\%|██████████████████████████████████████████████████████████████████████
███████████| 4704/4704 [00:00<00:00, 17729.88 examples/s]
[I 2024-06-20 07:26:59,629] A new study created in memory with name: hyper-
parameter-search
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
/tmp/ipykernel\_1104303/3918511221.py:37: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  learning\_rate=trial.suggest\_loguniform("learning\_rate", low=4e-5, high=0.01),
/tmp/ipykernel\_1104303/3918511221.py:38: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  weight\_decay=trial.suggest\_loguniform("weight\_decay", 4e-5, 0.01),
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/training\_args.py:1474: FutureWarning:
`evaluation\_strategy` is deprecated and will be removed in version 4.46 of 🤗
Transformers. Use `eval\_strategy` instead
  warnings.warn(
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'loss': 0.6208, 'grad\_norm': 4.609071254730225, 'learning\_rate':
0.00043125496300916487, 'epoch': 0.08503401360544217\}
\{'loss': 0.6261, 'grad\_norm': 0.8630306124687195, 'learning\_rate':
0.000412105097866662, 'epoch': 0.17006802721088435\}
\{'loss': 0.617, 'grad\_norm': 0.47822126746177673, 'learning\_rate':
0.0003929552327241591, 'epoch': 0.25510204081632654\}
\{'loss': 0.6055, 'grad\_norm': 1.0605601072311401, 'learning\_rate':
0.00037380536758165625, 'epoch': 0.3401360544217687\}
\{'loss': 0.6239, 'grad\_norm': 10.253633499145508, 'learning\_rate':
0.0003546555024391534, 'epoch': 0.42517006802721086\}
\{'loss': 0.6232, 'grad\_norm': 1.439030408859253, 'learning\_rate':
0.0003355056372966505, 'epoch': 0.5102040816326531\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[W 2024-06-20 07:50:13,769] Trial 0 failed with parameters: \{'learning\_rate':
0.00045040482815166775, 'weight\_decay': 0.00025689528868076927,
'num\_train\_epochs': 2\} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/optuna/study/\_optimize.py", line 196, in \_run\_trial
    value\_or\_values = func(trial)
                      \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/tmp/ipykernel\_1104303/3918511221.py", line 53, in objective
    result = trainer.train()
             \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 1885, in train
    return inner\_training\_loop(
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 2216, in \_inner\_training\_loop
    tr\_loss\_step = self.training\_step(model, inputs)
                   \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 3238, in training\_step
    loss = self.compute\_loss(model, inputs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/trainer.py", line 3264, in compute\_loss
    outputs = model(**inputs)
              \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 1691, in forward
    outputs = self.bert(
              \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 1137, in forward
    encoder\_outputs = self.encoder(
                      \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 690, in forward
    layer\_outputs = layer\_module(
                    \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 580, in forward
    self\_attention\_outputs = self.attention(
                             \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 519, in forward
    attention\_output = self.output(self\_outputs[0], hidden\_states)
                       \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/transformers/models/bert/modeling\_bert.py", line 461, in forward
    hidden\_states = self.dense(hidden\_states)
                    \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1532, in \_wrapped\_call\_impl
    return self.\_call\_impl(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/module.py", line 1541, in \_call\_impl
    return forward\_call(*args, **kwargs)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
  File "/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           \^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}\^{}
KeyboardInterrupt
[W 2024-06-20 07:50:13,775] Trial 0 failed with value None.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}, frame=single, framerule=2mm, rulecolor=\color{outerrorbackground}]
\textcolor{ansi-red}{---------------------------------------------------------------------------}
\textcolor{ansi-red}{KeyboardInterrupt}                         Traceback (most recent call last)
Cell \textcolor{ansi-green}{In[4], line 58}
\textcolor{ansi-green-intense}{\textbf{     56}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Optimizar hiperparámetros}
\textcolor{ansi-green-intense}{\textbf{     57}} study \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} optuna\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}create\_study(study\_name\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{hyper-parameter-search}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, direction\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{minimize}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"})
\textcolor{ansi-green}{---> 58} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{optimize\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{objective\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{5\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Reducir el número de trials}
\textcolor{ansi-green-intense}{\textbf{     60}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{print}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Mejor valor de pérdida:}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}best\_value)
\textcolor{ansi-green-intense}{\textbf{     61}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{print}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Mejores parámetros:}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}best\_params)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/study.py:451}, in \textcolor{ansi-cyan}{Study.optimize}\textcolor{ansi-blue}{(self, func, n\_trials, timeout, n\_jobs, catch, callbacks, gc\_after\_trial, show\_progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{    348}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{optimize}(
\textcolor{ansi-green-intense}{\textbf{    349}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    350}}     func: ObjectiveFuncType,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    357}}     show\_progress\_bar: \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{bool} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}},
\textcolor{ansi-green-intense}{\textbf{    358}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}:
\textcolor{ansi-green-intense}{\textbf{    359}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{188,188,188}}{    }\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""Optimize an objective function.}
\textcolor{ansi-green-intense}{\textbf{    360}} 
\textcolor{ansi-green-intense}{\textbf{    361}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    Optimization is done by choosing a suitable set of hyperparameter values from a given}
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    449}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{            If nested invocation of this method occurs.}
\textcolor{ansi-green-intense}{\textbf{    450}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    """}
\textcolor{ansi-green}{--> 451}     \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_optimize\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    452}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    453}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    454}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    455}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    456}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_jobs\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_jobs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    457}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{tuple\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{if}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{isinstance\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{Iterable\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{else}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    458}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    459}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    460}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{show\_progress\_bar\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{show\_progress\_bar\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    461}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:62}, in \textcolor{ansi-cyan}{\_optimize}\textcolor{ansi-blue}{(study, func, n\_trials, timeout, n\_jobs, catch, callbacks, gc\_after\_trial, show\_progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{     60}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{     61}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} n\_jobs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:
\textcolor{ansi-green}{---> 62}         \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_optimize\_sequential\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{     63}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     64}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     65}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{n\_trials\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     66}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{timeout\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     67}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     68}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{callbacks\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     69}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{gc\_after\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     70}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{reseed\_sampler\_rng\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{False}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     71}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{time\_start\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\textbf{None}\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     72}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{            \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{progress\_bar\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{progress\_bar\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{     73}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{     74}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green-intense}{\textbf{     75}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} n\_jobs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:159}, in \textcolor{ansi-cyan}{\_optimize\_sequential}\textcolor{ansi-blue}{(study, func, n\_trials, timeout, catch, callbacks, gc\_after\_trial, reseed\_sampler\_rng, time\_start, progress\_bar)}
\textcolor{ansi-green-intense}{\textbf{    156}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{break}}
\textcolor{ansi-green-intense}{\textbf{    158}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green}{--> 159}     frozen\_trial \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_run\_trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{study\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{catch\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    160}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{finally}}:
\textcolor{ansi-green-intense}{\textbf{    161}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# The following line mitigates memory problems that can be occurred in some}
\textcolor{ansi-green-intense}{\textbf{    162}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# environments (e.g., services that use computing containers such as GitHub Actions).}
\textcolor{ansi-green-intense}{\textbf{    163}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Please refer to the following PR for further details:}
\textcolor{ansi-green-intense}{\textbf{    164}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# https://github.com/optuna/optuna/pull/325.}
\textcolor{ansi-green-intense}{\textbf{    165}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} gc\_after\_trial:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:247}, in \textcolor{ansi-cyan}{\_run\_trial}\textcolor{ansi-blue}{(study, func, catch)}
\textcolor{ansi-green-intense}{\textbf{    240}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{assert}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Should not reach.}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}
\textcolor{ansi-green-intense}{\textbf{    242}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} (
\textcolor{ansi-green-intense}{\textbf{    243}}     frozen\_trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{==} TrialState\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}FAIL
\textcolor{ansi-green-intense}{\textbf{    244}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} func\_err \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green-intense}{\textbf{    245}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{isinstance}(func\_err, catch)
\textcolor{ansi-green-intense}{\textbf{    246}} ):
\textcolor{ansi-green}{--> 247}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{raise}} func\_err
\textcolor{ansi-green-intense}{\textbf{    248}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} frozen\_trial

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/optuna/study/\_optimize.py:196}, in \textcolor{ansi-cyan}{\_run\_trial}\textcolor{ansi-blue}{(study, func, catch)}
\textcolor{ansi-green-intense}{\textbf{    194}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} get\_heartbeat\_thread(trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_trial\_id, study\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_storage):
\textcolor{ansi-green-intense}{\textbf{    195}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green}{--> 196}         value\_or\_values \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{func\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    197}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{except}} exceptions\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}TrialPruned \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{as}} e:
\textcolor{ansi-green-intense}{\textbf{    198}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# TODO(mamu): Handle multi-objective cases.}
\textcolor{ansi-green-intense}{\textbf{    199}}         state \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} TrialState\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}PRUNED

Cell \textcolor{ansi-green}{In[4], line 53}, in \textcolor{ansi-cyan}{objective}\textcolor{ansi-blue}{(trial)}
\textcolor{ansi-green-intense}{\textbf{     35}} training\_args \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} TrainingArguments(
\textcolor{ansi-green-intense}{\textbf{     36}}     output\_dir\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}output\_dir,
\textcolor{ansi-green-intense}{\textbf{     37}}     learning\_rate\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}trial\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}suggest\_loguniform(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{learning\_rate}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}, low\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{4e-5}, high\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0.01}),
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{     45}}     disable\_tqdm\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{True}},
\textcolor{ansi-green-intense}{\textbf{     46}} )
\textcolor{ansi-green-intense}{\textbf{     47}} trainer \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} Trainer(
\textcolor{ansi-green-intense}{\textbf{     48}}     model\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}model,
\textcolor{ansi-green-intense}{\textbf{     49}}     args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}training\_args,
\textcolor{ansi-green-intense}{\textbf{     50}}     train\_dataset\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}dataset[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{train}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}],
\textcolor{ansi-green-intense}{\textbf{     51}}     eval\_dataset\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=}dataset[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{test}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"}],
\textcolor{ansi-green-intense}{\textbf{     52}} )
\textcolor{ansi-green}{---> 53} result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trainer\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{train\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{     54}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} result\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}training\_loss

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:1885}, in \textcolor{ansi-cyan}{Trainer.train}\textcolor{ansi-blue}{(self, resume\_from\_checkpoint, trial, ignore\_keys\_for\_eval, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1883}}         hf\_hub\_utils\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}enable\_progress\_bars()
\textcolor{ansi-green-intense}{\textbf{   1884}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1885}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inner\_training\_loop\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1886}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1887}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{resume\_from\_checkpoint\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{resume\_from\_checkpoint\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1888}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{trial\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1889}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ignore\_keys\_for\_eval\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ignore\_keys\_for\_eval\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1890}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:2216}, in \textcolor{ansi-cyan}{Trainer.\_inner\_training\_loop}\textcolor{ansi-blue}{(self, batch\_size, args, resume\_from\_checkpoint, trial, ignore\_keys\_for\_eval)}
\textcolor{ansi-green-intense}{\textbf{   2213}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}control \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}callback\_handler\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}on\_step\_begin(args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}control)
\textcolor{ansi-green-intense}{\textbf{   2215}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}accelerator\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}accumulate(model):
\textcolor{ansi-green}{-> 2216}     tr\_loss\_step \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{training\_step\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   2218}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} (
\textcolor{ansi-green-intense}{\textbf{   2219}}     args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}logging\_nan\_inf\_filter
\textcolor{ansi-green-intense}{\textbf{   2220}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} is\_torch\_xla\_available()
\textcolor{ansi-green-intense}{\textbf{   2221}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{and}} (torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}isnan(tr\_loss\_step) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}isinf(tr\_loss\_step))
\textcolor{ansi-green-intense}{\textbf{   2222}} ):
\textcolor{ansi-green-intense}{\textbf{   2223}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# if loss is nan or inf simply add the average of previous logged losses}
\textcolor{ansi-green-intense}{\textbf{   2224}}     tr\_loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} tr\_loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{/} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}state\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}global\_step \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_globalstep\_last\_logged)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:3238}, in \textcolor{ansi-cyan}{Trainer.training\_step}\textcolor{ansi-blue}{(self, model, inputs)}
\textcolor{ansi-green-intense}{\textbf{   3235}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} loss\_mb\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}reduce\_mean()\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}detach()\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}to(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}device)
\textcolor{ansi-green-intense}{\textbf{   3237}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{with}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}compute\_loss\_context\_manager():
\textcolor{ansi-green}{-> 3238}     loss \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{compute\_loss\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   3240}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{del}} inputs
\textcolor{ansi-green-intense}{\textbf{   3241}} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}cuda\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}empty\_cache()

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/trainer.py:3264}, in \textcolor{ansi-cyan}{Trainer.compute\_loss}\textcolor{ansi-blue}{(self, model, inputs, return\_outputs)}
\textcolor{ansi-green-intense}{\textbf{   3262}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green-intense}{\textbf{   3263}}     labels \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green}{-> 3264} outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{model\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   3265}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Save past state if it exists}
\textcolor{ansi-green-intense}{\textbf{   3266}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# TODO: this needs to be fixed and made cleaner later.}
\textcolor{ansi-green-intense}{\textbf{   3267}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}args\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}past\_index \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:1691}, in \textcolor{ansi-cyan}{BertForSequenceClassification.forward}\textcolor{ansi-blue}{(self, input\_ids, attention\_mask, token\_type\_ids, position\_ids, head\_mask, inputs\_embeds, labels, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{   1683}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{r}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green-intense}{\textbf{   1684}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{labels (`torch.LongTensor` of shape `(batch\_size,)`, *optional*):}
\textcolor{ansi-green-intense}{\textbf{   1685}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    Labels for computing the sequence classification/regression loss. Indices should be in `[0, {\ldots},}
\textcolor{ansi-green-intense}{\textbf{   1686}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    config.num\_labels - 1]`. If `config.num\_labels == 1` a regression loss is computed (Mean-Square loss), If}
\textcolor{ansi-green-intense}{\textbf{   1687}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{    `config.num\_labels > 1` a classification loss is computed (Cross-Entropy).}
\textcolor{ansi-green-intense}{\textbf{   1688}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green-intense}{\textbf{   1689}} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} return\_dict \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}config\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}use\_return\_dict
\textcolor{ansi-green}{-> 1691} outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{bert\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1692}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{input\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1693}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1694}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{token\_type\_ids\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{token\_type\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1695}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{position\_ids\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{position\_ids\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1696}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1697}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\_embeds\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{inputs\_embeds\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1698}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1699}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1700}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1701}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1703}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}]
\textcolor{ansi-green-intense}{\textbf{   1705}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}dropout(pooled\_output)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:1137}, in \textcolor{ansi-cyan}{BertModel.forward}\textcolor{ansi-blue}{(self, input\_ids, attention\_mask, token\_type\_ids, position\_ids, head\_mask, inputs\_embeds, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_values, use\_cache, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{   1130}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# Prepare head mask if needed}
\textcolor{ansi-green-intense}{\textbf{   1131}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# 1.0 in head\_mask indicate we keep the head}
\textcolor{ansi-green-intense}{\textbf{   1132}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# attention\_probs has shape bsz x n\_heads x N x N}
\textcolor{ansi-green-intense}{\textbf{   1133}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# input head\_mask has shape [num\_heads] or [num\_hidden\_layers x num\_heads]}
\textcolor{ansi-green-intense}{\textbf{   1134}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# and head\_mask is converted to shape [num\_hidden\_layers x batch x num\_heads x seq\_length x seq\_length]}
\textcolor{ansi-green-intense}{\textbf{   1135}} head\_mask \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}get\_head\_mask(head\_mask, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}config\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}num\_hidden\_layers)
\textcolor{ansi-green}{-> 1137} encoder\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{   1138}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{embedding\_output\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1139}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{extended\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1140}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1141}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1142}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_attention\_mask\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_extended\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1143}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_values\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_values\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1144}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{use\_cache\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{use\_cache\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1145}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1146}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1147}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{return\_dict\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{   1148}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1149}} sequence\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} encoder\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{   1150}} pooled\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}pooler(sequence\_output) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}pooler \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:690}, in \textcolor{ansi-cyan}{BertEncoder.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_values, use\_cache, output\_attentions, output\_hidden\_states, return\_dict)}
\textcolor{ansi-green-intense}{\textbf{    679}}     layer\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_gradient\_checkpointing\_func(
\textcolor{ansi-green-intense}{\textbf{    680}}         layer\_module\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\_\_call\_\_},
\textcolor{ansi-green-intense}{\textbf{    681}}         hidden\_states,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    687}}         output\_attentions,
\textcolor{ansi-green-intense}{\textbf{    688}}     )
\textcolor{ansi-green-intense}{\textbf{    689}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{--> 690}     layer\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{layer\_module\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    691}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    692}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    693}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{layer\_head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    694}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    695}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{encoder\_attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    696}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_value\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    697}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    698}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    700}} hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} layer\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{    701}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} use\_cache:

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:580}, in \textcolor{ansi-cyan}{BertLayer.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_value, output\_attentions)}
\textcolor{ansi-green-intense}{\textbf{    568}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(
\textcolor{ansi-green-intense}{\textbf{    569}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    570}}     hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    577}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tuple[torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor]:
\textcolor{ansi-green-intense}{\textbf{    578}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# decoder uni-directional self-attention cached key/values tuple is at positions 1,2}
\textcolor{ansi-green-intense}{\textbf{    579}}     self\_attn\_past\_key\_value \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} past\_key\_value[:\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{2}] \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} past\_key\_value \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{is}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}
\textcolor{ansi-green}{--> 580}     self\_attention\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}
\textcolor{ansi-green-intense}{\textbf{    581}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    582}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{attention\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    583}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{head\_mask\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    584}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\_attentions\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    585}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{        \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{past\_key\_value\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{=\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\_attn\_past\_key\_value\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}
\textcolor{ansi-green-intense}{\textbf{    586}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{    \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    587}}     attention\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} self\_attention\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{0}]
\textcolor{ansi-green-intense}{\textbf{    589}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# if decoder, the last output is tuple of self-attn cache}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:519}, in \textcolor{ansi-cyan}{BertAttention.forward}\textcolor{ansi-blue}{(self, hidden\_states, attention\_mask, head\_mask, encoder\_hidden\_states, encoder\_attention\_mask, past\_key\_value, output\_attentions)}
\textcolor{ansi-green-intense}{\textbf{    500}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(
\textcolor{ansi-green-intense}{\textbf{    501}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self},
\textcolor{ansi-green-intense}{\textbf{    502}}     hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    508}}     output\_attentions: Optional[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{bool}] \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{False}},
\textcolor{ansi-green-intense}{\textbf{    509}} ) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tuple[torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor]:
\textcolor{ansi-green-intense}{\textbf{    510}}     self\_outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}self(
\textcolor{ansi-green-intense}{\textbf{    511}}         hidden\_states,
\textcolor{ansi-green-intense}{\textbf{    512}}         attention\_mask,
\textcolor{ansi-green}{   ({\ldots})}
\textcolor{ansi-green-intense}{\textbf{    517}}         output\_attentions,
\textcolor{ansi-green-intense}{\textbf{    518}}     )
\textcolor{ansi-green}{--> 519}     attention\_output \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{output\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\_outputs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{[\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{0\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{]\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    520}}     outputs \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} (attention\_output,) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} self\_outputs[\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1}:]  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# add attentions if we output them}
\textcolor{ansi-green-intense}{\textbf{    521}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} outputs

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/transformers/models/bert/modeling\_bert.py:461}, in \textcolor{ansi-cyan}{BertSelfOutput.forward}\textcolor{ansi-blue}{(self, hidden\_states, input\_tensor)}
\textcolor{ansi-green-intense}{\textbf{    460}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}, hidden\_states: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor, input\_tensor: torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} torch\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}Tensor:
\textcolor{ansi-green}{--> 461}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{dense\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{hidden\_states\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{    462}}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}dropout(hidden\_states)
\textcolor{ansi-green-intense}{\textbf{    463}}     hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}LayerNorm(hidden\_states \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{+} input\_tensor)

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1532}, in \textcolor{ansi-cyan}{Module.\_wrapped\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1530}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_compiled\_call\_impl(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}args, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{*}kwargs)  \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# type: ignore[misc]}
\textcolor{ansi-green-intense}{\textbf{   1531}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{else}}:
\textcolor{ansi-green}{-> 1532}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{\_call\_impl\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/module.py:1541}, in \textcolor{ansi-cyan}{Module.\_call\_impl}\textcolor{ansi-blue}{(self, *args, **kwargs)}
\textcolor{ansi-green-intense}{\textbf{   1536}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# If we don't have any hooks, we want to skip the rest of the logic in}
\textcolor{ansi-green-intense}{\textbf{   1537}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# this function, and just call forward.}
\textcolor{ansi-green-intense}{\textbf{   1538}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{if}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{not}} (\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}\_forward\_pre\_hooks
\textcolor{ansi-green-intense}{\textbf{   1539}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_pre\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_backward\_hooks
\textcolor{ansi-green-intense}{\textbf{   1540}}         \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_hooks \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{\textbf{or}} \_global\_forward\_pre\_hooks):
\textcolor{ansi-green}{-> 1541}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{forward\_call\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{args\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{*\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{kwargs\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}
\textcolor{ansi-green-intense}{\textbf{   1543}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{   1544}}     result \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{None}}

File \textcolor{ansi-green}{\textasciitilde{}/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-packages/torch/nn/modules/linear.py:116}, in \textcolor{ansi-cyan}{Linear.forward}\textcolor{ansi-blue}{(self, input)}
\textcolor{ansi-green-intense}{\textbf{    115}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{forward}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{input}: Tensor) \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{-}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{>} Tensor:
\textcolor{ansi-green}{--> 116}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{return}} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{F\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{linear\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{(\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{input\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{weight\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{,\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ \strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{self\strut}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{bias\strut}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{)\strut}

\textcolor{ansi-red}{KeyboardInterrupt}: 
    \end{Verbatim}

    En esta versión del código, se han realizado varias modificaciones para
mejorar la eficiencia y resolver advertencias. Estas incluyen la
actualización del método de sugerencia de hiperparámetros
suggest\_loguniform a suggest\_float con log=True, la corrección de
evaluation\_strategy a eval\_strategy, la desactivación de tqdm para
reducir el tiempo de registro, y la gestión adecuada de pesos no
inicializados. Además, se ha reducido el tamaño del dataset para los
ensayos iniciales y se asegura el uso de GPU si está disponible, lo que
contribuye a una ejecución más rápida y eficiente.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{datasets}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{load\PYZus{}dataset}
\PY{k+kn}{from} \PY{n+nn}{transformers} \PY{k+kn}{import} \PY{p}{(}
    \PY{n}{AutoTokenizer}\PY{p}{,}
    \PY{n}{AutoModelForSequenceClassification}\PY{p}{,}
    \PY{n}{TrainingArguments}\PY{p}{,}
    \PY{n}{Trainer}\PY{p}{,}
\PY{p}{)}
\PY{k+kn}{import} \PY{n+nn}{torch}

\PY{c+c1}{\PYZsh{} Usar GPU si está disponible}
\PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Cargar dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZus{}corpus\PYZus{}v2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ade\PYZus{}corpus\PYZus{}v2\PYZus{}classification}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Reducir aún más el tamaño del dataset para ensayos iniciales}
\PY{n}{small\PYZus{}train\PYZus{}dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{)}\PY{p}{)}
\PY{n}{small\PYZus{}eval\PYZus{}dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Definir el nombre del modelo y tokenizer}
\PY{n}{model\PYZus{}name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bert\PYZhy{}base\PYZhy{}uncased}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{tokenizer} \PY{o}{=} \PY{n}{AutoTokenizer}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Función de preprocesamiento}
\PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{examples}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{tokenizer}\PY{p}{(}
        \PY{n}{examples}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{text}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{truncation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}length}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{64}
    \PY{p}{)}

\PY{c+c1}{\PYZsh{} Preprocesar el dataset}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\PY{n}{small\PYZus{}train\PYZus{}dataset} \PY{o}{=} \PY{n}{small\PYZus{}train\PYZus{}dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\PY{n}{small\PYZus{}eval\PYZus{}dataset} \PY{o}{=} \PY{n}{small\PYZus{}eval\PYZus{}dataset}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{,} \PY{n}{batched}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Función objetivo para optimización de hiperparámetros}
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{:} \PY{n}{optuna}\PY{o}{.}\PY{n}{Trial}\PY{p}{)}\PY{p}{:}
    \PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    \PY{n}{output\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ade\PYZhy{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{trial\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Directorio de salida único para cada ensayo}
    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{output\PYZus{}dir}\PY{p}{,} \PY{n}{exist\PYZus{}ok}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

    \PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
        \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}
        \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
        \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mf}{4e\PYZhy{}5}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{log}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
        \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Reducir el máximo a 3 épocas}
        \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
        \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
        \PY{n}{eval\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}           \PY{c+c1}{\PYZsh{} Evaluar al final de cada época}
        \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{n}{output\PYZus{}dir}\PY{p}{,}          \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
        \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{500}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 500 pasos}
        \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
        \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
        \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
        \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{small\PYZus{}train\PYZus{}dataset}\PY{p}{,}
        \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{small\PYZus{}eval\PYZus{}dataset}\PY{p}{,}
    \PY{p}{)}
    \PY{n}{result} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{result}\PY{o}{.}\PY{n}{training\PYZus{}loss}

\PY{c+c1}{\PYZsh{} Optimizar hiperparámetros}
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}\PY{n}{study\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hyper\PYZhy{}parameter\PYZhy{}search}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{direction}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{minimize}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objective}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Reducir el número de trials a 3}

\PY{c+c1}{\PYZsh{} Entrenar con el mejor conjunto de hiperparámetros}
\PY{n}{best\PYZus{}trial} \PY{o}{=} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}
\PY{n}{model} \PY{o}{=} \PY{n}{AutoModelForSequenceClassification}\PY{o}{.}\PY{n}{from\PYZus{}pretrained}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{)}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
\PY{n}{training\PYZus{}args} \PY{o}{=} \PY{n}{TrainingArguments}\PY{p}{(}
    \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{final\PYZhy{}model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{weight\PYZus{}decay}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weight\PYZus{}decay}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{num\PYZus{}train\PYZus{}epochs}\PY{o}{=}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}train\PYZus{}epochs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{per\PYZus{}device\PYZus{}train\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
    \PY{n}{per\PYZus{}device\PYZus{}eval\PYZus{}batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Aumentar tamaño de lote}
    \PY{n}{eval\PYZus{}strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}           \PY{c+c1}{\PYZsh{} Evaluar al final de cada época}
    \PY{n}{logging\PYZus{}dir}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{final\PYZhy{}model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}       \PY{c+c1}{\PYZsh{} Guardar logs en el mismo directorio}
    \PY{n}{logging\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{500}\PY{p}{,}               \PY{c+c1}{\PYZsh{} Registrar cada 500 pasos}
    \PY{n}{disable\PYZus{}tqdm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
\PY{p}{)}
\PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
    \PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
    \PY{n}{args}\PY{o}{=}\PY{n}{training\PYZus{}args}\PY{p}{,}
    \PY{n}{train\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{eval\PYZus{}dataset}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
\PY{p}{)}
\PY{n}{trainer}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor valor de pérdida:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}value}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejores parámetros:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor trial:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Map: 100\%|██████████████████████████████████████████████████████████████████████
███████████| 4704/4704 [00:00<00:00, 16241.83 examples/s]
Map: 100\%|██████████████████████████████████████████████████████████████████████
█████████████| 500/500 [00:00<00:00, 17101.18 examples/s]
Map: 100\%|██████████████████████████████████████████████████████████████████████
██████████████| 100/100 [00:00<00:00, 8745.60 examples/s]
[I 2024-06-20 08:00:15,228] A new study created in memory with name: hyper-
parameter-search
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:01:19,538] Trial 0 finished with value: 0.6301901340484619 and
parameters: \{'learning\_rate': 0.0013548425105920966, 'weight\_decay':
0.000844581377013946, 'num\_train\_epochs': 1\}. Best is trial 0 with value:
0.6301901340484619.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.724229097366333, 'eval\_runtime': 2.8348,
'eval\_samples\_per\_second': 35.276, 'eval\_steps\_per\_second': 2.469, 'epoch': 1.0\}
\{'train\_runtime': 63.5725, 'train\_samples\_per\_second': 7.865,
'train\_steps\_per\_second': 0.503, 'train\_loss': 0.6301901340484619, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:02:23,023] Trial 1 finished with value: 0.760809600353241 and
parameters: \{'learning\_rate': 0.001476016748798422, 'weight\_decay':
0.00367499601830561, 'num\_train\_epochs': 1\}. Best is trial 0 with value:
0.6301901340484619.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.6591594219207764, 'eval\_runtime': 2.8204,
'eval\_samples\_per\_second': 35.456, 'eval\_steps\_per\_second': 2.482, 'epoch': 1.0\}
\{'train\_runtime': 62.9091, 'train\_samples\_per\_second': 7.948,
'train\_steps\_per\_second': 0.509, 'train\_loss': 0.760809600353241, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
[I 2024-06-20 08:03:28,469] Trial 2 finished with value: 0.5697887539863586 and
parameters: \{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}. Best is trial 2 with value:
0.5697887539863586.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'eval\_loss': 0.4735482335090637, 'eval\_runtime': 2.8675,
'eval\_samples\_per\_second': 34.874, 'eval\_steps\_per\_second': 2.441, 'epoch': 1.0\}
\{'train\_runtime': 64.712, 'train\_samples\_per\_second': 7.727,
'train\_steps\_per\_second': 0.494, 'train\_loss': 0.5697887539863586, 'epoch': 1.0\}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Some weights of BertForSequenceClassification were not initialized from the
model checkpoint at bert-base-uncased and are newly initialized:
['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it
for predictions and inference.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'loss': 0.615, 'grad\_norm': 0.9341108202934265, 'learning\_rate':
0.0001298759888794938, 'epoch': 0.42517006802721086\}
\{'loss': 0.6097, 'grad\_norm': 2.0760040283203125, 'learning\_rate':
3.381386692720549e-05, 'epoch': 0.8503401360544217\}
\{'eval\_loss': 0.5997103452682495, 'eval\_runtime': 151.5124,
'eval\_samples\_per\_second': 31.047, 'eval\_steps\_per\_second': 1.94, 'epoch': 1.0\}
\{'train\_runtime': 2566.1987, 'train\_samples\_per\_second': 7.331,
'train\_steps\_per\_second': 0.458, 'train\_loss': 0.609258729584363, 'epoch': 1.0\}
Mejor valor de pérdida: 0.5697887539863586
Mejores parámetros: \{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}
Mejor trial: FrozenTrial(number=2, state=1, values=[0.5697887539863586],
datetime\_start=datetime.datetime(2024, 6, 20, 8, 2, 23, 24407),
datetime\_complete=datetime.datetime(2024, 6, 20, 8, 3, 28, 469023),
params=\{'learning\_rate': 0.00022593811083178214, 'weight\_decay':
0.00018438428760538783, 'num\_train\_epochs': 1\}, user\_attrs=\{\}, system\_attrs=\{\},
intermediate\_values=\{\}, distributions=\{'learning\_rate':
FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'weight\_decay':
FloatDistribution(high=0.01, log=True, low=4e-05, step=None),
'num\_train\_epochs': IntDistribution(high=3, log=False, low=1, step=1)\},
trial\_id=2, value=None)
    \end{Verbatim}

    \hypertarget{desarrollo-de-un-sistema-de-prunning-automuxe1tico}{%
\subsection{4. Desarrollo de un sistema de prunning
automático:}\label{desarrollo-de-un-sistema-de-prunning-automuxe1tico}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Implementar y configurar el prunning de ensayos en Optuna para detener
  automáticamente los ensayos menos prometedores y reducir el tiempo de
  computación. \textbackslash{}
\item
  Comparar el rendimiento y la eficiencia del proceso de optimización
  con y sin prunning.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{prune} \PY{k}{as} \PY{n+nn}{prune}

\PY{k}{class} \PY{n+nc}{ModeloPruned}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
    \PY{k}{def} \PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{super}\PY{p}{(}\PY{n}{PrunedModel}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{784}\PY{p}{,} \PY{l+m+mi}{256}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{)}
        \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}

    \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
        \PY{n}{x} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc3}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{k}{return} \PY{n}{x}

\PY{c+c1}{\PYZsh{} Example usage}
\PY{n}{modelo} \PY{o}{=} \PY{n}{ModeloPruned}\PY{p}{(}\PY{p}{)}
\PY{n}{parametros\PYZus{}a\PYZus{}podar} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{n}{modelo}\PY{o}{.}\PY{n}{fc1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{modeloo}\PY{o}{.}\PY{n}{fc2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}
\PY{n}{prune}\PY{o}{.}\PY{n}{global\PYZus{}unstructured}\PY{p}{(}
    \PY{n}{parametros\PYZus{}a\PYZus{}podar}\PY{p}{,}
    \PY{n}{metodo\PYZus{}pruning}\PY{o}{=}\PY{n}{prune}\PY{o}{.}\PY{n}{L1Unstructured}\PY{p}{,}
    \PY{n}{cantidad}\PY{o}{=}\PY{l+m+mf}{0.2}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{integraciuxf3n-de-tuxe9cnicas-de-transfer-learning}{%
\subsection{5. Integración de técnicas de transfer
learning:}\label{integraciuxf3n-de-tuxe9cnicas-de-transfer-learning}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Experimentar con la optimización de modelos preentrenados en tareas
  específicas, ajustando hiperparámetros para fine-tuning.
  \textbackslash{}
\item
  Evaluar la efectividad de Optuna en la selección de hiperparámetros
  que maximizan el transfer learning.
\end{enumerate}

    En este ejemplo práctico de optimización de hiperparámetros, abordaremos
un problema de clasificación binaria.

(basado en
http://pytorch.org/tutorials/beginner/transfer\_learning\_tutorial.html)

    Utilizaremos el conjunto de datos Hormigas contra Abejas, que forma
parte del conjunto de datos ImageNet. Deberá descargarlo desde aquí:
Hormigas contra abejas. Contiene 400 imágenes, \textasciitilde250 de
entrenamiento y \textasciitilde150 de validación (prueba).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}wget\PY{+w}{ }https://download.pytorch.org/tutorial/hymenoptera\PYZus{}data.zip
\PY{o}{!}unzip\PY{+w}{ }hymenoptera\PYZus{}data.zip
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{torch}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{as} \PY{n+nn}{optim}
\PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k+kn}{import} \PY{n}{lr\PYZus{}scheduler}
\PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{backends}\PY{n+nn}{.}\PY{n+nn}{cudnn} \PY{k}{as} \PY{n+nn}{cudnn}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{torchvision}
\PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k+kn}{import} \PY{n}{datasets}\PY{p}{,} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{time}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k+kn}{import} \PY{n}{Image}
\PY{k+kn}{from} \PY{n+nn}{tempfile} \PY{k+kn}{import} \PY{n}{TemporaryDirectory}
\PY{k+kn}{import} \PY{n+nn}{copy}

\PY{n}{cudnn}\PY{o}{.}\PY{n}{benchmark} \PY{o}{=} \PY{k+kc}{True}
\PY{n}{plt}\PY{o}{.}\PY{n}{ion}\PY{p}{(}\PY{p}{)}   \PY{c+c1}{\PYZsh{} interactive mode}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<contextlib.ExitStack at 0x71c9a3111be0>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{data\PYZus{}transforms} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomResizedCrop}\PY{p}{(}\PY{l+m+mi}{224}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomHorizontalFlip}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Normalize}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.485}\PY{p}{,} \PY{l+m+mf}{0.456}\PY{p}{,} \PY{l+m+mf}{0.406}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{0.229}\PY{p}{,} \PY{l+m+mf}{0.224}\PY{p}{,} \PY{l+m+mf}{0.225}\PY{p}{]}\PY{p}{)}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Resize}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{CenterCrop}\PY{p}{(}\PY{l+m+mi}{224}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
        \PY{n}{transforms}\PY{o}{.}\PY{n}{Normalize}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.485}\PY{p}{,} \PY{l+m+mf}{0.456}\PY{p}{,} \PY{l+m+mf}{0.406}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{0.229}\PY{p}{,} \PY{l+m+mf}{0.224}\PY{p}{,} \PY{l+m+mf}{0.225}\PY{p}{]}\PY{p}{)}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./hymenoptera\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{image\PYZus{}datasets} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{datasets}\PY{o}{.}\PY{n}{ImageFolder}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{,}
                                          \PY{n}{data\PYZus{}transforms}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{)}
                  \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{dataloaders} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}
                                             \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
              \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{dataset\PYZus{}sizes} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{n}{class\PYZus{}names} \PY{o}{=} \PY{n}{image\PYZus{}datasets}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{classes}

\PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda:0}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    La siguiente función se utilizará para entrenar el modelo:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{train\PYZus{}model}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{criterion}\PY{p}{,} \PY{n}{optimizer}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{since} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}

    \PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{copy}\PY{o}{.}\PY{n}{deepcopy}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{l+m+mf}{0.0}

    \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}\PY{p}{:}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epoch }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{epoch}\PY{p}{,} \PY{n}{num\PYZus{}epochs} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{*} \PY{l+m+mi}{10}\PY{p}{)}

        \PY{k}{for} \PY{n}{phase} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
            \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)} 
            \PY{k}{else}\PY{p}{:}
                \PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}  

            \PY{n}{running\PYZus{}loss} \PY{o}{=} \PY{l+m+mf}{0.0}
            \PY{n}{running\PYZus{}corrects} \PY{o}{=} \PY{l+m+mi}{0}

            \PY{k}{for} \PY{n}{inputs}\PY{p}{,} \PY{n}{labels} \PY{o+ow}{in} \PY{n}{dataloaders}\PY{p}{[}\PY{n}{phase}\PY{p}{]}\PY{p}{:}
                \PY{n}{inputs} \PY{o}{=} \PY{n}{inputs}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
                \PY{n}{labels} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}

                \PY{n}{optimizer}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}

                \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{set\PYZus{}grad\PYZus{}enabled}\PY{p}{(}\PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                    \PY{n}{outputs} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}
                    \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{preds} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{outputs}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
                    \PY{n}{loss} \PY{o}{=} \PY{n}{criterion}\PY{p}{(}\PY{n}{outputs}\PY{p}{,} \PY{n}{labels}\PY{p}{)}

                    \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                        \PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
                        \PY{n}{optimizer}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

                \PY{n}{running\PYZus{}loss} \PY{o}{+}\PY{o}{=} \PY{n}{loss}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)} \PY{o}{*} \PY{n}{inputs}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
                \PY{n}{running\PYZus{}corrects} \PY{o}{+}\PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{preds} \PY{o}{==} \PY{n}{labels}\PY{o}{.}\PY{n}{data}\PY{p}{)}

            \PY{n}{epoch\PYZus{}loss} \PY{o}{=} \PY{n}{running\PYZus{}loss} \PY{o}{/} \PY{n}{dataset\PYZus{}sizes}\PY{p}{[}\PY{n}{phase}\PY{p}{]}
            \PY{n}{epoch\PYZus{}acc} \PY{o}{=} \PY{n}{running\PYZus{}corrects}\PY{o}{.}\PY{n}{double}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{dataset\PYZus{}sizes}\PY{p}{[}\PY{n}{phase}\PY{p}{]}

            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ Loss: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{ Acc: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
                \PY{n}{phase}\PY{p}{,} \PY{n}{epoch\PYZus{}loss}\PY{p}{,} \PY{n}{epoch\PYZus{}acc}\PY{p}{)}\PY{p}{)}

            \PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{and} \PY{n}{epoch\PYZus{}acc} \PY{o}{\PYZgt{}} \PY{n}{best\PYZus{}acc}\PY{p}{:}
                \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{n}{epoch\PYZus{}acc}
                \PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{copy}\PY{o}{.}\PY{n}{deepcopy}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{)}

        \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{trial}\PY{o}{.}\PY{n}{report}\PY{p}{(}\PY{n}{epoch\PYZus{}acc}\PY{p}{,} \PY{n}{epoch}\PY{p}{)}
        \PY{k}{if} \PY{n}{trial}\PY{o}{.}\PY{n}{should\PYZus{}prune}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{k}{raise} \PY{n}{optuna}\PY{o}{.}\PY{n}{TrialPruned}\PY{p}{(}\PY{p}{)}

    \PY{n}{time\PYZus{}elapsed} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{since}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training complete in }\PY{l+s+si}{\PYZob{}:.0f\PYZcb{}}\PY{l+s+s1}{m }\PY{l+s+si}{\PYZob{}:.0f\PYZcb{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
        \PY{n}{time\PYZus{}elapsed} \PY{o}{/}\PY{o}{/} \PY{l+m+mi}{60}\PY{p}{,} \PY{n}{time\PYZus{}elapsed} \PY{o}{\PYZpc{}} \PY{l+m+mi}{60}\PY{p}{)}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best val Acc: }\PY{l+s+si}{\PYZob{}:4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{best\PYZus{}acc}\PY{p}{)}\PY{p}{)}

    \PY{n}{model}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{best\PYZus{}model\PYZus{}wts}\PY{p}{)}
    \PY{k}{return} \PY{n}{model}\PY{p}{,} \PY{n}{best\PYZus{}acc}
\end{Verbatim}
\end{tcolorbox}

    Para empezar, es fundamental crear la Función Objetivo. Esta función
toma una configuración de hiperparámetros y devuelve su puntuación de
evaluación (valor objetivo). Optuna resuelve el problema de la
optimización de hiperparámetros al maximizar o minimizar esta Función
Objetivo.

La Función Objetivo encapsula el proceso estándar de entrenamiento del
modelo. Definimos nuestro modelo, configuramos optimizadores y funciones
de pérdida, evaluamos métricas, entre otros pasos. En este ejemplo,
evaluaremos la métrica de precisión en el conjunto de validación.
También devolveremos su valor desde la Función Objetivo para que Optuna
lo utilice en la optimización.

Dentro de la Función Objetivo, debemos definir los hiperparámetros que
deseamos optimizar. En Optuna, es posible optimizar diferentes tipos de
hiperparámetros, como:

\begin{itemize}
\tightlist
\item
  Números reales (floats).
\item
  Números enteros (integers).
\item
  Categóricos discretos.
\end{itemize}

    En nuestro ejemplo, optimizaremos tres hiperparámetros:

\begin{itemize}
\tightlist
\item
  Red preentrenada. Dado que el conjunto de datos de ``Hormigas
  vs.~Abejas'' es pequeño, utilizaremos transfer learning para obtener
  un modelo de buena calidad. Hemos elegido una de las redes entrenadas
  en ImageNet y reemplazamos las últimas capas completamente conectadas
  responsables de la clasificación.
\item
  Optimizador: SGD, Adam.
\item
  Tasa de aprendizaje: de 1e-4 a 1e-2.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{objetivo}\PY{p}{(}\PY{n}{trial}\PY{p}{)}\PY{p}{:}
    
    \PY{c+c1}{\PYZsh{} Hiperparámetros que queremos optimizar}
    \PY{n}{params} \PY{o}{=} \PY{p}{\PYZob{}}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{alexnet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vgg16}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}2}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{optimizer\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SGD}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{p}{\PYZcb{}}
    
    \PY{c+c1}{\PYZsh{} Obtener el modelo preentrenado}
    \PY{n}{model} \PY{o}{=} \PY{n}{obtener\PYZus{}modelo}\PY{p}{(}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Definir criterio}
    \PY{n}{criterion} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Configurar optimizador}
    \PY{n}{optimizer} \PY{o}{=} \PY{n+nb}{getattr}\PY{p}{(}
        \PY{n}{torch}\PY{o}{.}\PY{n}{optim}\PY{p}{,} \PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{optimizer\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
    \PY{p}{)}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{n}{params}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Entrenar el modelo}
    \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{criterion}\PY{p}{,} \PY{n}{optimizer}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Guardar el mejor modelo para cada prueba}
    \PY{c+c1}{\PYZsh{} torch.save(mejor\PYZus{}modelo.state\PYZus{}dict(), f\PYZdq{}modelo\PYZus{}prueba\PYZus{}\PYZob{}prueba.number\PYZcb{}.pth\PYZdq{})}
    
    \PY{c+c1}{\PYZsh{} Devolver precisión (Valor Objetivo) de la prueba actual}
    \PY{k}{return} \PY{n}{best\PYZus{}acc}
\end{Verbatim}
\end{tcolorbox}

    Nota: Para obtener un modelo preentrenado por su nombre, añadiremos una
función get\_model:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{obtener\PYZus{}modelo}\PY{p}{(}\PY{n}{model\PYZus{}name}\PY{p}{:} \PY{n+nb}{str} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}  
    \PY{k}{if} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{resnet18}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{resnet18}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fc}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{fc} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{elif} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{alexnet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{alexnet}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{classifier}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{elif} \PY{n}{model\PYZus{}name} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vgg16}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{vgg16}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{in\PYZus{}features} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{classifier}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{in\PYZus{}features}
        \PY{n}{model}\PY{o}{.}\PY{n}{classifier} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{in\PYZus{}features}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{k}{return} \PY{n}{model}
\end{Verbatim}
\end{tcolorbox}

    Para empezar a optimizar nuestra Función Objetivo, creamos un nuevo
estudio:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} sampler: queremos usar un muestreador TPE}
\PY{c+c1}{\PYZsh{} pruner: utilizamos MedianPruner para interrumpir pruebas poco prometedoras}
\PY{c+c1}{\PYZsh{} direction: la dirección del estudio es \PYZdq{}maximizar\PYZdq{} porque queremos maximizar la precisión}
\PY{c+c1}{\PYZsh{} n\PYZus{}trials: Número de pruebas}

\PY{n}{sampler} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{samplers}\PY{o}{.}\PY{n}{TPESampler}\PY{p}{(}\PY{p}{)}    
\PY{n}{study} \PY{o}{=} \PY{n}{optuna}\PY{o}{.}\PY{n}{create\PYZus{}study}\PY{p}{(}
    \PY{n}{sampler}\PY{o}{=}\PY{n}{sampler}\PY{p}{,}
    \PY{n}{pruner}\PY{o}{=}\PY{n}{optuna}\PY{o}{.}\PY{n}{pruners}\PY{o}{.}\PY{n}{MedianPruner}\PY{p}{(}
        \PY{n}{n\PYZus{}startup\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{n\PYZus{}warmup\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{interval\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{3}
    \PY{p}{)}\PY{p}{,}
    \PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{maximize}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{study}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{func}\PY{o}{=}\PY{n}{objetivo}\PY{p}{,} \PY{n}{n\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:24:20,991] A new study created in memory with name: no-
name-9d0d4d94-6f95-41df-860a-24a0b5c9dc69
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 0/4
----------
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1312130/1625103487.py:6: FutureWarning: suggest\_loguniform has
been deprecated in v3.0.0. This feature will be removed in v6.0.0. See
https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest\_float({\ldots},
log=True) instead.
  "lr": trial.suggest\_loguniform('lr', 1e-4, 1e-2),
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
train Loss: 0.6493 Acc: 0.6393
val Loss: 0.4960 Acc: 0.7843

Epoch 1/4
----------
train Loss: 0.5164 Acc: 0.7582
val Loss: 0.3734 Acc: 0.8693

Epoch 2/4
----------
train Loss: 0.4524 Acc: 0.8033
val Loss: 0.3143 Acc: 0.9150

Epoch 3/4
----------
train Loss: 0.3931 Acc: 0.8484
val Loss: 0.2712 Acc: 0.9020

Epoch 4/4
----------
train Loss: 0.3783 Acc: 0.8197
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:25:33,401] Trial 0 finished with value: 0.934640522875817 and
parameters: \{'model\_name': 'resnet18', 'lr': 0.0008709086527787754,
'optimizer\_name': 'SGD'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.2431 Acc: 0.9346

Training complete in 1m 12s
Best val Acc: 0.934641
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/torchvision/models/\_utils.py:223: UserWarning: Arguments other than a
weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed
in the future. The current behavior is equivalent to passing
`weights=VGG16\_Weights.IMAGENET1K\_V1`. You can also use
`weights=VGG16\_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 0/4
----------
train Loss: 790.5330 Acc: 0.4344
val Loss: 8.5681 Acc: 0.4575

Epoch 1/4
----------
train Loss: 1.6542 Acc: 0.5164
val Loss: 0.8113 Acc: 0.5686

Epoch 2/4
----------
train Loss: 0.8495 Acc: 0.4631
val Loss: 0.7626 Acc: 0.5425

Epoch 3/4
----------
train Loss: 0.9628 Acc: 0.4549
val Loss: 0.9402 Acc: 0.4510

Epoch 4/4
----------
train Loss: 21.8259 Acc: 0.4672
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:32:37,827] Trial 1 finished with value: 0.5686274509803921 and
parameters: \{'model\_name': 'vgg16', 'lr': 0.005366941939750931,
'optimizer\_name': 'Adam'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.7004 Acc: 0.5425

Training complete in 7m 4s
Best val Acc: 0.568627
Epoch 0/4
----------
train Loss: 0.6187 Acc: 0.6475
val Loss: 0.4011 Acc: 0.8693

Epoch 1/4
----------
train Loss: 0.5138 Acc: 0.7418
val Loss: 0.2897 Acc: 0.9346

Epoch 2/4
----------
train Loss: 0.4449 Acc: 0.7705
val Loss: 0.2511 Acc: 0.9216

Epoch 3/4
----------
train Loss: 0.4241 Acc: 0.7992
val Loss: 0.2305 Acc: 0.9150

Epoch 4/4
----------
train Loss: 0.3511 Acc: 0.8402
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[I 2024-06-20 09:34:05,586] Trial 2 finished with value: 0.934640522875817 and
parameters: \{'model\_name': 'resnet18', 'lr': 0.0016671673715747957,
'optimizer\_name': 'SGD'\}. Best is trial 0 with value: 0.934640522875817.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
val Loss: 0.2090 Acc: 0.9346

Training complete in 1m 28s
Best val Acc: 0.934641
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{best\PYZus{}trial} \PY{o}{=} \PY{n}{study}\PY{o}{.}\PY{n}{best\PYZus{}trial}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{🎉🎉🎉}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mejor prueba:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Número de prueba: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{number}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Modelo seleccionado: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Learning rate (lr): }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Optimizador seleccionado: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Precisión obtenida: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Fecha y hora de inicio: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{datetime\PYZus{}start}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Fecha y hora de finalización: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{datetime\PYZus{}complete}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  Métricas intermedias:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{step}\PY{p}{,} \PY{n}{value} \PY{o+ow}{in} \PY{n}{best\PYZus{}trial}\PY{o}{.}\PY{n}{intermediate\PYZus{}values}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{    Paso }\PY{l+s+si}{\PYZob{}}\PY{n}{step}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
🎉🎉🎉
Mejor prueba:
  Número de prueba: 0
  Modelo seleccionado: resnet18
  Learning rate (lr): 0.0008709086527787754
  Optimizador seleccionado: SGD
  Precisión obtenida: 0.934640522875817
  Fecha y hora de inicio: 2024-06-20 09:24:20.993162
  Fecha y hora de finalización: 2024-06-20 09:25:33.401369
  Métricas intermedias:
    Paso 0: 0.7843137254901961
    Paso 1: 0.869281045751634
    Paso 2: 0.9150326797385621
    Paso 3: 0.9019607843137255
    Paso 4: 0.934640522875817
    \end{Verbatim}

    \hypertarget{anuxe1lisis-de-sensibilidad-y-robustez}{%
\subsection{6. Análisis de sensibilidad y
robustez:}\label{anuxe1lisis-de-sensibilidad-y-robustez}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Realizar un análisis de sensibilidad para identificar qué
  hiperparámetros son más influyentes en el rendimiento del modelo.
  \textbackslash{}
\item
  Investigar la robustez de los modelos optimizados en condiciones de
  variación de datos, como ruido o cambios en la distribución de los
  datos.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{plotly}
\PY{n}{plotly}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
'5.22.0'
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{pickle}

\PY{c+c1}{\PYZsh{} Guardar el estudio actual en un archivo}
\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{study.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
    \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{study}\PY{p}{,} \PY{n}{f}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{pickle}

\PY{c+c1}{\PYZsh{} Para cargar el estudio después de reiniciar el kernel}
\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{study.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
    \PY{n}{study} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{f}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/home/abraham/miniconda3/envs/jupyter-ipykernel/lib/python3.12/site-
packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update
jupyter and ipywidgets. See
https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{plot\PYZus{}parallel\PYZus{}coordinate}\PY{p}{(}\PY{n}{study}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{renderer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{browser}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Opening in existing browser session.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}parallel\PYZus{}coordinate}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1386379/437109074.py:1: ExperimentalWarning:

plot\_parallel\_coordinate is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Parallel Coordinate Plot'\}>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_65_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{plot\PYZus{}contour}\PY{p}{(}\PY{n}{study}\PY{p}{,} \PY{n}{params}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{optimizer\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{n}{renderer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{browser}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Opening in existing browser session.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{IPython} \PY{k+kn}{import} \PY{n}{display}
\PY{n}{display}\PY{o}{.}\PY{n}{Image}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{https://i.ibb.co/56X2BYB/download2.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{10}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_67_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}optuna.visualization.matplotlib.plot\PYZus{}contour(study, params=[\PYZsq{}optimizer\PYZus{}name\PYZsq{},\PYZsq{}model\PYZus{}name\PYZsq{}])}
\end{Verbatim}
\end{tcolorbox}

    Gráficos de cortes para cada uno de los hiperparámetros:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}slice}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1386379/2375574420.py:1: ExperimentalWarning:

plot\_slice is experimental (supported from v2.2.0). The interface can change in
the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([<Axes: xlabel='lr', ylabel='Objective Value'>,
       <Axes: xlabel='model\_name'>, <Axes: xlabel='optimizer\_name'>],
      dtype=object)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_70_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Importancia de los hiperparámetros:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{sklearn}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}param\PYZus{}importances}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/1785110159.py:3: ExperimentalWarning:

plot\_param\_importances is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'left': 'Hyperparameter Importances'\}, xlabel='Hyperparameter
Importance', ylabel='Hyperparameter'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_72_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Trazar el historial de optimización de todos los ensayos de un estudio:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}optimization\PYZus{}history}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/1455980257.py:1: ExperimentalWarning:

plot\_optimization\_history is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Optimization History Plot'\}, xlabel='Trial',
ylabel='Objective Value'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_74_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Curvas de aprendizaje de los ensayos:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{optuna}\PY{o}{.}\PY{n}{visualization}\PY{o}{.}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{plot\PYZus{}intermediate\PYZus{}values}\PY{p}{(}\PY{n}{study}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/tmp/ipykernel\_1420446/2140463885.py:1: ExperimentalWarning:

plot\_intermediate\_values is experimental (supported from v2.2.0). The interface
can change in the future.

    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<Axes: title=\{'center': 'Intermediate Values Plot'\}, xlabel='Step',
ylabel='Intermediate Value'>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{automatizaciuxf3n-y-escalabilidad-del-proceso-de-optimizaciuxf3n-opcional}{%
\subsection{7. Automatización y escalabilidad del proceso de
optimización
(opcional):}\label{automatizaciuxf3n-y-escalabilidad-del-proceso-de-optimizaciuxf3n-opcional}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Desarrollar un framework automatizado que pueda escalar la
  optimización de hiperparámetros a múltiples máquinas o GPUs.
  \textbackslash{}
\item
  Utilizar Optuna en un entorno de com putación distribuida para manejar
  grandes volúmenes de pruebas de hiperparámetros de manera eficiente.
\end{enumerate}

    \hypertarget{documentaciuxf3n-de-resultados}{%
\subsection{8. Documentación de
resultados:}\label{documentaciuxf3n-de-resultados}}

    \begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Preparar una documentación que describa los métodos utilizados, los
  resultados obtenidos y las recomendaciones para futuras
  investigaciones. \textbackslash{}
\item
  Publicar los hallazgos en un artículo de conferencia o revista,
  enfocándose en cómo la optimización de hiperparámetros puede mejorar
  significativamente los modelos de aprendizaje profundo (opcional).
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
